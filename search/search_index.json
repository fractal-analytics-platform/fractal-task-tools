{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Fractal Command-line Client's documentation!","text":"<p>Fractal is a framework developed at the BioVisionCenter to process bioimaging data at scale in the OME-Zarr format and prepare the images for interactive visualization.</p> <p>This documentatin website describes the Fractal Task Tools package, which provides some basic shared tools for building tasks for the Fractal framework. Find more information about Fractal in general and the other repositories at the Fractal home page.</p> <p>This project is under active development \ud83d\udd28. If you need help or found a bug, open an issue here.</p>"},{"location":"#contributors-and-license","title":"Contributors and license","text":"<p>Fractal was conceived in the Liberali Lab at the Friedrich Miescher Institute for Biomedical Research and in the Pelkmans Lab at the University of Zurich by @jluethi and @gusqgm. The Fractal project is now developed at the BioVisionCenter at the University of Zurich and the project lead is with @jluethi. The core development is done under contract by eXact lab S.r.l..</p> <p>Unless otherwise specified, Fractal components are released under the BSD 3-Clause License, and copyright is with the BioVisionCenter at the University of Zurich.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#040-unreleased","title":"0.4.0 (unreleased)","text":"<ul> <li>Schema generation:<ul> <li>Compute <code>default</code> as specified in <code>default_factory</code>, when possible (#75, #93).</li> <li>Take into accounts <code>default</code> values set through <code>Field</code> (#93).</li> <li>Transform single-element <code>\"allOf\": [{\"$ref\": X}]</code> arrays into single <code>\"$ref\": X</code> key-value pair (#79).</li> <li>Support providing <code>description</code> through <code>Field</code>, with priority over docstrings (#89).</li> <li>Propagate checks for forbidden non-<code>null</code> defaults of nullable properties to nested properties (#103).</li> </ul> </li> <li>CLI commands:<ul> <li>Add <code>--verbose</code> option to <code>fractal-manifest check</code> (#80).</li> <li>In <code>fractal-manifest check</code>, display all manifest mismatches rather than the first one only (#88).</li> </ul> </li> <li>Dependencies:<ul> <li>Drop support for <code>python&lt;3.11</code> (#92).</li> <li>Drop support for <code>pydantic&lt;2.11.0</code> (#92).</li> <li>Drop support to <code>pydantic&gt;=2.13</code> (#108).</li> <li>Support <code>docstring-parser</code> v0.17 (#76).</li> </ul> </li> <li>Internal:<ul> <li>Update <code>ruff</code> configuration (#106).</li> </ul> </li> </ul>"},{"location":"changelog/#030","title":"0.3.0","text":"<p>See https://fractal-analytics-platform.github.io/fractal-task-tools/usage/run_task/#log-configuration for a description of the new logging-related feature.</p> <ul> <li>Introduce logging-configuration environment variables (#70, #71).</li> <li>Mark <code>logger_name</code> argument of <code>run_fractal_task</code> as deprecated (#70).</li> <li>Dependencies:<ul> <li>Bump pydantic requirement to <code>&gt;=2.6.0,&lt;=2.13.0</code> (#74).</li> </ul> </li> <li>Testing:<ul> <li>Add test with <code>lowest-direct</code> resolution scheme for Python 3.11 and 3.12 (#74).</li> </ul> </li> <li>Development:<ul> <li>Adopt <code>uv</code> for development (#74).</li> </ul> </li> </ul>"},{"location":"changelog/#021","title":"0.2.1","text":"<ul> <li>Improve support for tagged/non-tagged union arguments (#68).</li> <li>Testing:<ul> <li>Add <code>fractal-ome-zarr-hcs-stitching</code> to external-packages tests (#64).</li> <li>Add <code>operetta-compose</code> to external-packages tests (#58).</li> <li>Add <code>APx_fractal_task_collection</code> to external-packages tests (#61).</li> <li>Add <code>zmb-fractal-tasks</code> to external-packages tests (#60).</li> <li>Add <code>example-tasks</code> to external-packages tests (#68).</li> <li>Add <code>fractal-cellpose-sam-task</code> to external-packages tests (#68).</li> </ul> </li> </ul>"},{"location":"changelog/#020","title":"0.2.0","text":"<p>[yanked due to a mistake upon release]</p>"},{"location":"changelog/#011","title":"0.1.1","text":"<ul> <li>Support Python3.14 (#57).</li> </ul>"},{"location":"changelog/#010","title":"0.1.0","text":"<ul> <li>Deprecate <code>--fractal-server-2-13</code> option (#45).</li> <li>Broader support for unions of type and <code>None</code> (#53).</li> <li>Support pydantic v2.12 (#55).</li> </ul>"},{"location":"changelog/#0014","title":"0.0.14","text":"<ul> <li>Replace <code>DOCS_LINK=\"\"</code> with <code>DOCS_LINK=None</code> (#42).</li> <li>Test manifest agains <code>fractal-server</code> schema for external packages (#42).</li> <li>Test multiple JSON-Schema drafts, for external packages (#39).</li> </ul>"},{"location":"changelog/#0013","title":"0.0.13","text":"<ul> <li>Support Python 3.13 (#35).</li> <li>Support <code>pydantic&lt;=2.11.7</code> (#37).</li> </ul>"},{"location":"development/","title":"Contribute to Fractal Task Tools development","text":""},{"location":"development/#setup-environment","title":"Setup environment","text":"<p>We use uv to manage the development environment and the dependencies - see https://docs.astral.sh/uv/getting-started/installation/ for methods to install it. From the <code>fractal-task-tools</code> root folder, you can get started through <pre><code># Create a new virtual environment in `.venv`\nuv venv\n\n# Install both the required dependencies and the optional dev/docs dependencies\nuv sync --all-extras\n</code></pre></p>"},{"location":"development/#set-up-pre-commit","title":"Set up <code>pre-commit</code>","text":"<p>We use pre-commit to run several checks on files that are being committed. To set it up locally, you should run <pre><code># Install pre-commit globally (e.g. via `pipx`)\npipx install pre-commit\n\n# Add the pre-commit hook to your local repository\npre-commit install\n</code></pre></p>"},{"location":"development/#make-a-release","title":"Make a release","text":"<pre><code>uv run --no-sync --frozen bumpver update --patch --dry\n</code></pre>"},{"location":"development/#tests","title":"Tests","text":"<p>Run e.g. one of these commands <pre><code>uv run --no-sync --frozen pytest\nuv run --no-sync --frozen pytest -s -vvv --log-cli-level info --full-trace\n</code></pre></p>"},{"location":"development/#documentation","title":"Documentation","text":"<p>The documentation is built with <code>mkdocs</code>, and we bundle a module from sphinx-argparse plugin, customized to our needs.</p> <p>To build or server the documentation locally run <pre><code>uv run --no-sync --frozen mkdocs serve --config-file mkdocs.yml  # serves the docs at http://127.0.0.1:8000\n\nuv run --no-sync --frozen mkdocs build --config-file mkdocs.yml  # creates a build in the `site` folder\n</code></pre></p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>fractal_task_tools<ul> <li>_args_schemas</li> <li>_cli</li> <li>_cli_tools</li> <li>_create_manifest</li> <li>_deepdiff</li> <li>_descriptions</li> <li>_generatejsonschema</li> <li>_package_name_tools</li> <li>_signature_constraints</li> <li>_task_arguments</li> <li>_task_docs</li> <li>_titles</li> <li>_union_types</li> <li>logging_config</li> <li>task_models</li> <li>task_wrapper</li> </ul> </li> <li>fractal-manifest<ul> <li>create</li> <li>check</li> </ul> </li> </ul>"},{"location":"reference/fractal-manifest/","title":"fractal-manifest","text":"<p><code>fractal-manifest</code> command-line interface</p> <pre><code>fractal-manifest [-h] {create,check} ...\n</code></pre>"},{"location":"reference/fractal-manifest/check/","title":"check","text":"<p>Check existing manifest file</p> <pre><code>fractal-manifest check [-h] --package PACKAGE  [--task-list-path TASK_LIST_PATH]\n        [--ignore-keys-order IGNORE_KEYS_ORDER] [--verbose]\n</code></pre>"},{"location":"reference/fractal-manifest/check/#named-arguments","title":"Named Arguments","text":"<ul> <li> <p><code>--package</code>: Example: 'fractal_tasks_core'</p> </li> <li> <p><code>--task-list-path</code>: Dot-separated path to the <code>task_list.py</code> module, relative to the package root (default value: 'dev.task_list'). Default: <code>\"dev.task_list\"</code>.</p> </li> <li> <p><code>--ignore-keys-order</code>: Ignore the order of dictionary keys when comparing manifests (default value: False). Default: <code>False</code>.</p> </li> <li> <p><code>--verbose</code>: Make logs more verbose (default value: False). Default: <code>False</code>.</p> </li> </ul>"},{"location":"reference/fractal-manifest/create/","title":"create","text":"<p>Create new manifest file</p> <pre><code>fractal-manifest create [-h] --package PACKAGE  [--task-list-path\n        TASK_LIST_PATH]\n</code></pre>"},{"location":"reference/fractal-manifest/create/#named-arguments","title":"Named Arguments","text":"<ul> <li> <p><code>--package</code>: Example: 'fractal_tasks_core'</p> </li> <li> <p><code>--task-list-path</code>: Dot-separated path to the <code>task_list.py</code> module, relative to the package root (default value: 'dev.task_list'). Default: <code>\"dev.task_list\"</code>.</p> </li> </ul>"},{"location":"reference/fractal_task_tools/","title":"fractal_task_tools","text":""},{"location":"reference/fractal_task_tools/_args_schemas/","title":"_args_schemas","text":""},{"location":"reference/fractal_task_tools/_args_schemas/#fractal_task_tools._args_schemas._remove_attributes_from_descriptions","title":"<code>_remove_attributes_from_descriptions(old_schema)</code>","text":"<p>Keeps only the description part of the docstrings: e.g from <pre><code>'Custom class for Omero-channel window, based on OME-NGFF v0.4.\\n'\n'\\n'\n'Attributes:\\n'\n'min: Do not change. It will be set to `0` by default.\\n'\n'max: Do not change. It will be set according to bitdepth of the images\\n'\n'    by default (e.g. 65535 for 16 bit images).\\n'\n'start: Lower-bound rescaling value for visualization.\\n'\n'end: Upper-bound rescaling value for visualization.'\n</code></pre> to <code>'Custom class for Omero-channel window, based on OME-NGFF v0.4.\\n'</code>.</p> PARAMETER DESCRIPTION <code>old_schema</code> <p>TBD</p> <p> TYPE: <code>_Schema</code> </p> Source code in <code>src/fractal_task_tools/_args_schemas.py</code> <pre><code>def _remove_attributes_from_descriptions(old_schema: _Schema) -&gt; _Schema:\n    \"\"\"\n    Keeps only the description part of the docstrings: e.g from\n    ```\n    'Custom class for Omero-channel window, based on OME-NGFF v0.4.\\\\n'\n    '\\\\n'\n    'Attributes:\\\\n'\n    'min: Do not change. It will be set to `0` by default.\\\\n'\n    'max: Do not change. It will be set according to bitdepth of the images\\\\n'\n    '    by default (e.g. 65535 for 16 bit images).\\\\n'\n    'start: Lower-bound rescaling value for visualization.\\\\n'\n    'end: Upper-bound rescaling value for visualization.'\n    ```\n    to `'Custom class for Omero-channel window, based on OME-NGFF v0.4.\\\\n'`.\n\n    Args:\n        old_schema: TBD\n    \"\"\"\n    new_schema = old_schema.copy()\n    if \"$defs\" in new_schema:\n        for name, definition in new_schema[\"$defs\"].items():\n            if \"description\" in definition.keys():\n                parsed_docstring = docparse(definition[\"description\"])\n                new_schema[\"$defs\"][name][\"description\"] = (\n                    parsed_docstring.short_description\n                )\n            elif \"title\" in definition.keys():\n                title = definition[\"title\"]\n                new_schema[\"$defs\"][name][\"description\"] = (\n                    f\"Missing description for {title}.\"\n                )\n            else:\n                new_schema[\"$defs\"][name][\"description\"] = \"Missing description\"\n    logging.info(\"[_remove_attributes_from_descriptions] END\")\n    return new_schema\n</code></pre>"},{"location":"reference/fractal_task_tools/_args_schemas/#fractal_task_tools._args_schemas._remove_top_level_single_element_allof","title":"<code>_remove_top_level_single_element_allof(schema)</code>","text":"<p>Transform <code>\"allOf\": [{\"$ref\": X}]</code> into <code>\"$ref\": X</code></p> Source code in <code>src/fractal_task_tools/_args_schemas.py</code> <pre><code>def _remove_top_level_single_element_allof(schema: _Schema) -&gt; _Schema:\n    \"\"\"\n    Transform `\"allOf\": [{\"$ref\": X}]` into `\"$ref\": X`\n    \"\"\"\n    old_schema = deepcopy(schema)\n    for arg_name, old_arg_schema in old_schema[\"properties\"].items():\n        if (\n            \"allOf\" in old_arg_schema.keys()\n            and isinstance(old_arg_schema[\"allOf\"], list)\n            and len(old_arg_schema[\"allOf\"]) == 1\n            and isinstance(old_arg_schema[\"allOf\"][0], dict)\n            and list(old_arg_schema[\"allOf\"][0].keys()) == [\"$ref\"]\n            and \"$ref\" not in old_arg_schema.keys()\n        ):\n            new_arg_schema: dict[str, Any] = deepcopy(old_arg_schema)\n            key_value = new_arg_schema.pop(\"allOf\")[0]\n            new_arg_schema.update(key_value)\n            schema[\"properties\"][arg_name] = new_arg_schema\n            logging.debug(f\"Replaced single-item allOf with {key_value} \")\n    return schema\n</code></pre>"},{"location":"reference/fractal_task_tools/_args_schemas/#fractal_task_tools._args_schemas.create_schema_for_single_task","title":"<code>create_schema_for_single_task(executable, package=None, pydantic_models=None, task_function=None, verbose=False)</code>","text":"<p>Main function to create a JSON Schema of task arguments</p> <p>This function can be used in two ways:</p> <ol> <li><code>task_function</code> argument is <code>None</code>, <code>package</code> is set, and <code>executable</code>     is a path relative to that package.</li> <li><code>task_function</code> argument is provided, <code>executable</code> is an absolute path     to the function module, and <code>package</code> is `None. This is useful for     testing.</li> </ol> Source code in <code>src/fractal_task_tools/_args_schemas.py</code> <pre><code>def create_schema_for_single_task(\n    executable: str,\n    package: Optional[str] = None,\n    pydantic_models: Optional[list[tuple[str, str, str]]] = None,\n    task_function: Optional[Callable] = None,\n    verbose: bool = False,\n) -&gt; _Schema:\n    \"\"\"\n    Main function to create a JSON Schema of task arguments\n\n    This function can be used in two ways:\n\n    1. `task_function` argument is `None`, `package` is set, and `executable`\n        is a path relative to that package.\n    2. `task_function` argument is provided, `executable` is an absolute path\n        to the function module, and `package` is `None. This is useful for\n        testing.\n    \"\"\"\n\n    DEFINITIONS_KEY = \"$defs\"\n\n    logging.info(\"[create_schema_for_single_task] START\")\n    if task_function is None:\n        usage = \"1\"\n        # Usage 1 (standard)\n        if package is None:\n            raise ValueError(\n                \"Cannot call `create_schema_for_single_task with \"\n                f\"{task_function=} and {package=}. Exit.\"\n            )\n        if os.path.isabs(executable):\n            raise ValueError(\n                \"Cannot call `create_schema_for_single_task with \"\n                f\"{task_function=} and absolute {executable=}. Exit.\"\n            )\n    else:\n        usage = \"2\"\n        # Usage 2 (testing)\n        if package is not None:\n            raise ValueError(\n                \"Cannot call `create_schema_for_single_task with \"\n                f\"{task_function=} and non-None {package=}. Exit.\"\n            )\n        if not os.path.isabs(executable):\n            raise ValueError(\n                \"Cannot call `create_schema_for_single_task with \"\n                f\"{task_function=} and non-absolute {executable=}. Exit.\"\n            )\n\n    # Extract function from module\n    if usage == \"1\":\n        # Extract the function name (for the moment we assume the function has\n        # the same name as the module)\n        function_name = Path(executable).with_suffix(\"\").name\n        # Extract the function object\n        task_function = _extract_function(\n            package_name=package,\n            module_relative_path=executable,\n            function_name=function_name,\n            verbose=verbose,\n        )\n    else:\n        # The function object is already available, extract its name\n        function_name = task_function.__name__\n\n    if verbose:\n        logging.info(f\"[create_schema_for_single_task] {function_name=}\")\n        logging.info(f\"[create_schema_for_single_task] {task_function=}\")\n\n    # Validate function signature against some custom constraints\n    _validate_function_signature(task_function)\n\n    # Create and clean up schema\n    schema = _create_schema_for_function(task_function)\n    schema = _remove_attributes_from_descriptions(schema)\n    schema = _remove_top_level_single_element_allof(schema)\n\n    # Include titles for custom-model-typed arguments\n    schema = _include_titles(schema, definitions_key=DEFINITIONS_KEY, verbose=verbose)\n\n    # Include main title\n    if schema.get(\"title\") is None:\n\n        def to_camel_case(snake_str):\n            return \"\".join(x.capitalize() for x in snake_str.lower().split(\"_\"))\n\n        schema[\"title\"] = to_camel_case(task_function.__name__)\n\n    # Include descriptions of function. Note: this function works both\n    # for usages 1 or 2 (see docstring).\n    function_args_descriptions = _get_function_args_descriptions(\n        package_name=package,\n        module_path=executable,\n        function_name=function_name,\n        verbose=verbose,\n    )\n\n    schema = _insert_function_args_descriptions(\n        schema=schema,\n        descriptions=function_args_descriptions,\n        verbose=verbose,\n    )\n\n    if pydantic_models is not None:\n        # Check that model names are unique\n        pydantic_models_names = [item[2] for item in pydantic_models]\n        duplicate_class_names = [\n            name for name, count in Counter(pydantic_models_names).items() if count &gt; 1\n        ]\n        if duplicate_class_names:\n            pydantic_models_str = \"  \" + \"\\n  \".join(map(str, pydantic_models))\n            raise ValueError(\n                \"Cannot parse docstrings for models with non-unique names \"\n                f\"{duplicate_class_names}, in\\n{pydantic_models_str}\"\n            )\n\n        # Extract model-attribute descriptions and insert them into schema\n        for package_name, module_relative_path, class_name in pydantic_models:\n            attrs_descriptions = _get_class_attrs_descriptions(\n                package_name=package_name,\n                module_relative_path=module_relative_path,\n                class_name=class_name,\n            )\n            schema = _insert_class_attrs_descriptions(\n                schema=schema,\n                class_name=class_name,\n                descriptions=attrs_descriptions,\n                definition_key=DEFINITIONS_KEY,\n            )\n\n    logging.info(\"[create_schema_for_single_task] END\")\n    return schema\n</code></pre>"},{"location":"reference/fractal_task_tools/_cli/","title":"_cli","text":""},{"location":"reference/fractal_task_tools/_cli/#fractal_task_tools._cli._parse_arguments","title":"<code>_parse_arguments(sys_argv=None)</code>","text":"<p>Parse <code>sys.argv</code> or custom CLI arguments.</p> PARAMETER DESCRIPTION <code>sys_argv</code> <p>If set, overrides <code>sys.argv</code> (useful for testing).</p> <p> TYPE: <code>list[str] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/fractal_task_tools/_cli.py</code> <pre><code>def _parse_arguments(sys_argv: list[str] | None = None) -&gt; ap.Namespace:\n    \"\"\"\n    Parse `sys.argv` or custom CLI arguments.\n\n    Arguments:\n        sys_argv: If set, overrides `sys.argv` (useful for testing).\n    \"\"\"\n    if sys_argv is None:\n        sys_argv = sys.argv[:]\n    args = main_parser.parse_args(sys_argv[1:])\n    return args\n</code></pre>"},{"location":"reference/fractal_task_tools/_cli_tools/","title":"_cli_tools","text":""},{"location":"reference/fractal_task_tools/_cli_tools/#fractal_task_tools._cli_tools.check_manifest","title":"<code>check_manifest(*, raw_package_name, manifest, ignore_keys_order, verbose)</code>","text":"<p>Write manifest to file.</p> PARAMETER DESCRIPTION <code>raw_package_name</code> <p> TYPE: <code>str</code> </p> <code>manifest</code> <p>The manifest object</p> <p> TYPE: <code>str</code> </p> <code>ignore_keys_order</code> <p>Whether to ignore keys order.</p> <p> TYPE: <code>bool</code> </p> Source code in <code>src/fractal_task_tools/_cli_tools.py</code> <pre><code>def check_manifest(\n    *,\n    raw_package_name: str,\n    manifest: str,\n    ignore_keys_order: bool,\n    verbose: bool,\n) -&gt; None:\n    \"\"\"\n    Write manifest to file.\n\n    Arguments:\n        raw_package_name:\n        manifest: The manifest object\n        ignore_keys_order: Whether to ignore keys order.\n    \"\"\"\n\n    package_name = normalize_package_name(raw_package_name)\n    logging.info(f\"[check_manifest] {package_name=}\")\n\n    imported_package = import_module(package_name)\n    package_root_dir = Path(imported_package.__file__).parent\n    manifest_path = (package_root_dir / MANIFEST_FILENAME).as_posix()\n    logging.info(f\"[check_manifest] {os.getcwd()=}\")\n    logging.info(f\"[check_manifest] {package_root_dir=}\")\n    logging.info(f\"[check_manifest] {manifest_path=}\")\n\n    with open(manifest_path, \"r\") as f:\n        old_manifest = json.load(f)\n\n    if manifest == old_manifest:\n        logging.info(\"[check_manifest] On-disk manifest is up to date.\")\n    else:\n        logging.error(\"[check_manifest] On-disk manifest is not up to date.\")\n        deepdiff(\n            old_object=old_manifest,\n            new_object=manifest,\n            path=\"manifest\",\n            ignore_keys_order=ignore_keys_order,\n            verbose=verbose,\n        )\n        if ERRORS.tot_errors &gt; 0:\n            logging.error(f\"[check_manifest] Found {ERRORS.tot_errors} errors.\")\n            for old_object, new_object, msg in ERRORS.data:\n                print(msg)\n                if verbose:\n                    print(f\"OLD:\\n{json.dumps(old_object)}\")\n                    print(f\"NEW:\\n{json.dumps(new_object)}\")\n                    print()\n            sys.exit(\"New/old manifests differ\")\n    logging.info(\"[check_manifest] END\")\n</code></pre>"},{"location":"reference/fractal_task_tools/_cli_tools/#fractal_task_tools._cli_tools.write_manifest_to_file","title":"<code>write_manifest_to_file(*, raw_package_name, manifest)</code>","text":"<p>Write manifest to file.</p> PARAMETER DESCRIPTION <code>raw_package_name</code> <p> TYPE: <code>str</code> </p> <code>manifest</code> <p>The manifest object</p> <p> TYPE: <code>str</code> </p> Source code in <code>src/fractal_task_tools/_cli_tools.py</code> <pre><code>def write_manifest_to_file(\n    *,\n    raw_package_name: str,\n    manifest: str,\n) -&gt; None:\n    \"\"\"\n    Write manifest to file.\n\n    Arguments:\n        raw_package_name:\n        manifest: The manifest object\n    \"\"\"\n    logging.info(\"[write_manifest_to_file] START\")\n\n    package_name = normalize_package_name(raw_package_name)\n    logging.info(f\"[write_manifest_to_file] {package_name=}\")\n\n    imported_package = import_module(package_name)\n    package_root_dir = Path(imported_package.__file__).parent\n    manifest_path = (package_root_dir / MANIFEST_FILENAME).as_posix()\n    logging.info(f\"[write_manifest_to_file] {os.getcwd()=}\")\n    logging.info(f\"[write_manifest_to_file] {package_root_dir=}\")\n    logging.info(f\"[write_manifest_to_file] {manifest_path=}\")\n\n    with open(manifest_path, \"w\") as f:\n        json.dump(manifest, f, indent=2)\n        f.write(\"\\n\")\n\n    logging.info(\"[write_manifest_to_file] END\")\n</code></pre>"},{"location":"reference/fractal_task_tools/_create_manifest/","title":"_create_manifest","text":"<p>Generate JSON schemas for task arguments and combine them into a manifest.</p>"},{"location":"reference/fractal_task_tools/_create_manifest/#fractal_task_tools._create_manifest.create_manifest","title":"<code>create_manifest(*, raw_package_name, task_list_path)</code>","text":"<p>Create the package manifest based on a <code>task_list.py</code> module</p> PARAMETER DESCRIPTION <code>raw_package_name</code> <p>The name of the package. Note that this name must be importable (after normalization).</p> <p> TYPE: <code>str</code> </p> <code>task_list_path</code> <p>Relative path to the <code>task_list.py</code> module, with respect to the package root (example <code>dev.task_list</code>).</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>Task-package manifest.</p> Source code in <code>src/fractal_task_tools/_create_manifest.py</code> <pre><code>def create_manifest(\n    *,\n    raw_package_name: str,\n    task_list_path: str,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Create the package manifest based on a `task_list.py` module\n\n    Arguments:\n        raw_package_name:\n            The name of the package. Note that this name must be importable\n            (after normalization).\n        task_list_path:\n            Relative path to the `task_list.py` module, with respect to the\n            package root (example `dev.task_list`).\n\n    Returns:\n        Task-package manifest.\n    \"\"\"\n\n    # Preliminary validation\n    if \"/\" in task_list_path or task_list_path.endswith(\".py\"):\n        raise ValueError(f\"Invalid {task_list_path=} (valid example: `dev.task_list`).\")\n\n    # Normalize package name\n    package_name = normalize_package_name(raw_package_name)\n\n    logging.info(f\"Start generating a new manifest for {package_name}\")\n\n    # Prepare an empty manifest\n    manifest = dict(\n        manifest_version=MANIFEST_VERSION,\n        task_list=[],\n        has_args_schemas=True,\n        args_schema_version=ARGS_SCHEMA_VERSION,\n        authors=None,\n    )\n\n    # Import the task-list module\n    task_list_module = import_module(f\"{package_name}.{task_list_path}\")\n\n    # Load TASK_LIST\n    TASK_LIST: list[_BaseTask] = getattr(task_list_module, \"TASK_LIST\")\n\n    # Load INPUT_MODELS\n    try:\n        INPUT_MODELS = getattr(task_list_module, \"INPUT_MODELS\")\n    except AttributeError:\n        INPUT_MODELS = []\n        logging.warning(\n            \"No `INPUT_MODELS` found in task_list module. Setting it to `[]`.\"\n        )\n\n    # Load AUTHORS\n    try:\n        manifest[\"authors\"] = getattr(task_list_module, \"AUTHORS\")\n    except AttributeError:\n        logging.warning(\"No `AUTHORS` found in task_list module.\")\n\n    # Load DOCS_LINK\n    try:\n        DOCS_LINK = getattr(task_list_module, \"DOCS_LINK\")\n        # Transform empty string into None\n        if DOCS_LINK == \"\":\n            DOCS_LINK = None\n            logging.warning(\"`DOCS_LINK=` transformed into `DOCS_LINK=None`.\")\n    except AttributeError:\n        DOCS_LINK = None\n        logging.warning(\"No `DOCS_LINK` found in task_list module.\")\n\n    # Loop over TASK_LIST, and append the proper task dictionaries\n    # to manifest[\"task_list\"]\n    for task_obj in TASK_LIST:\n        # Convert Pydantic object to dictionary\n        task_dict = task_obj.model_dump(\n            exclude={\n                \"meta_init\",\n                \"executable_init\",\n                \"meta\",\n                \"executable\",\n            },\n            exclude_unset=True,\n        )\n        task_dict[\"type\"] = task_obj.type\n\n        # Copy some properties from `task_obj` to `task_dict`\n        if task_obj.executable_non_parallel is not None:\n            task_dict[\"executable_non_parallel\"] = task_obj.executable_non_parallel\n        if task_obj.executable_parallel is not None:\n            task_dict[\"executable_parallel\"] = task_obj.executable_parallel\n        if task_obj.meta_non_parallel is not None:\n            task_dict[\"meta_non_parallel\"] = task_obj.meta_non_parallel\n        if task_obj.meta_parallel is not None:\n            task_dict[\"meta_parallel\"] = task_obj.meta_parallel\n\n        # Autogenerate JSON Schemas for non-parallel/parallel task arguments\n        for kind in [\"non_parallel\", \"parallel\"]:\n            executable = task_dict.get(f\"executable_{kind}\")\n            if executable is not None:\n                logging.info(f\"[{executable}] START\")\n                schema = create_schema_for_single_task(\n                    executable,\n                    package=package_name,\n                    pydantic_models=INPUT_MODELS,\n                )\n\n                validate_arguments(\n                    task_type=task_obj.type,\n                    schema=schema,\n                    executable_kind=kind,\n                )\n\n                logging.info(f\"[{executable}] END (new schema)\")\n                task_dict[f\"args_schema_{kind}\"] = schema\n\n        # Compute and set `docs_info`\n        docs_info = task_dict.get(\"docs_info\")\n        if docs_info is None:\n            docs_info = create_docs_info(\n                executable_non_parallel=task_obj.executable_non_parallel,\n                executable_parallel=task_obj.executable_parallel,\n                package=package_name,\n            )\n        elif docs_info.startswith(\"file:\"):\n            docs_info = read_docs_info_from_file(\n                docs_info=docs_info,\n                task_list_path=task_list_module.__file__,\n            )\n        if docs_info is not None:\n            task_dict[\"docs_info\"] = docs_info\n\n        # Set `docs_link`\n        if DOCS_LINK is not None:\n            task_dict[\"docs_link\"] = DOCS_LINK\n\n        # Append task\n        manifest[\"task_list\"].append(task_dict)\n    return manifest\n</code></pre>"},{"location":"reference/fractal_task_tools/_deepdiff/","title":"_deepdiff","text":""},{"location":"reference/fractal_task_tools/_deepdiff/#fractal_task_tools._deepdiff.Errors","title":"<code>Errors</code>","text":"<p>An item of <code>self._data</code> is made of the old JSON object, the new JSON object and the error message.</p> Source code in <code>src/fractal_task_tools/_deepdiff.py</code> <pre><code>class Errors:\n    \"\"\"\n    An item of `self._data` is made of the old JSON object, the new JSON object\n    and the error message.\n    \"\"\"\n\n    _data: list[tuple[JSONType, JSONType, str]]\n\n    def __init__(self):\n        self._data = []\n\n    def reset_state(self):\n        self._data = []\n\n    def append(self: Self, item: tuple[JSONType, JSONType, str]):\n        self._data.append(item)\n\n    @property\n    def tot_errors(self: Self) -&gt; int:\n        return len(self._data)\n\n    @property\n    def messages_str(self: Self) -&gt; str:\n        return str([item[2] for item in self._data])\n\n    @property\n    def data(self: Self) -&gt; list[tuple[JSONType, JSONType, str]]:\n        return self._data\n</code></pre>"},{"location":"reference/fractal_task_tools/_descriptions/","title":"_descriptions","text":""},{"location":"reference/fractal_task_tools/_descriptions/#fractal_task_tools._descriptions._get_class_attrs_descriptions","title":"<code>_get_class_attrs_descriptions(package_name, module_relative_path, class_name)</code>","text":"<p>Extract class-attribute descriptions from an imported module</p> PARAMETER DESCRIPTION <code>package_name</code> <p>Example <code>fractal_tasks_core</code>.</p> <p> TYPE: <code>str</code> </p> <code>module_relative_path</code> <p>Example <code>lib_channels.py</code>.</p> <p> TYPE: <code>str</code> </p> <code>class_name</code> <p>Example <code>OmeroChannel</code>.</p> <p> TYPE: <code>str</code> </p> Source code in <code>src/fractal_task_tools/_descriptions.py</code> <pre><code>def _get_class_attrs_descriptions(\n    package_name: str, module_relative_path: str, class_name: str\n) -&gt; dict[str, str]:\n    \"\"\"\n    Extract class-attribute descriptions from an imported module\n\n    Args:\n        package_name: Example `fractal_tasks_core`.\n        module_relative_path: Example `lib_channels.py`.\n        class_name: Example `OmeroChannel`.\n    \"\"\"\n\n    if not module_relative_path.endswith(\".py\"):\n        raise ValueError(f\"Module {module_relative_path} must end with '.py'\")\n\n    # Get the class ast.ClassDef object\n    package_path = Path(import_module(package_name).__file__).parent\n    module_path = package_path / module_relative_path\n    descriptions = _get_class_attrs_descriptions_from_file(\n        module_path=module_path,\n        class_name=class_name,\n    )\n    logging.info(f\"[_get_class_attrs_descriptions] END ({class_name=})\")\n    return descriptions\n</code></pre>"},{"location":"reference/fractal_task_tools/_descriptions/#fractal_task_tools._descriptions._get_class_attrs_descriptions_from_file","title":"<code>_get_class_attrs_descriptions_from_file(*, module_path, class_name)</code>","text":"<p>Extract class-attribute descriptions from a Python script</p> PARAMETER DESCRIPTION <code>module_path</code> <p>Example <code>/something/my_class.py</code>.</p> <p> TYPE: <code>Path</code> </p> <code>class_name</code> <p>Example <code>OmeroChannel</code>.</p> <p> TYPE: <code>str</code> </p> Source code in <code>src/fractal_task_tools/_descriptions.py</code> <pre><code>def _get_class_attrs_descriptions_from_file(\n    *,\n    module_path: Path,\n    class_name: str,\n) -&gt; dict[str, str]:\n    \"\"\"\n    Extract class-attribute descriptions from a Python script\n\n    Args:\n        module_path: Example `/something/my_class.py`.\n        class_name: Example `OmeroChannel`.\n    \"\"\"\n    tree = ast.parse(module_path.read_text())\n    try:\n        _class = next(\n            c\n            for c in ast.walk(tree)\n            if (isinstance(c, ast.ClassDef) and c.name == class_name)\n        )\n    except StopIteration:\n        raise RuntimeError(f\"Cannot find {class_name=} in {module_path}.\")\n    docstring = ast.get_docstring(_class)\n    parsed_docstring = docparse(docstring)\n    descriptions = {\n        x.arg_name: _sanitize_description(x.description)\n        if x.description\n        else \"Missing description\"\n        for x in parsed_docstring.params\n    }\n    return descriptions\n</code></pre>"},{"location":"reference/fractal_task_tools/_descriptions/#fractal_task_tools._descriptions._get_function_args_descriptions","title":"<code>_get_function_args_descriptions(*, package_name, module_path, function_name, verbose=False)</code>","text":"<p>Extract argument descriptions from a function.</p> PARAMETER DESCRIPTION <code>package_name</code> <p>Example <code>fractal_tasks_core</code>.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>module_path</code> <p>This must be an absolute path like <code>/some/module.py</code> (if <code>package_name</code> is <code>None</code>) or a relative path like <code>something.py</code> (if <code>package_name</code> is not <code>None</code>).</p> <p> TYPE: <code>str</code> </p> <code>function_name</code> <p>Example <code>create_ome_zarr</code>.</p> <p> TYPE: <code>str</code> </p> Source code in <code>src/fractal_task_tools/_descriptions.py</code> <pre><code>def _get_function_args_descriptions(\n    *,\n    package_name: Optional[str],\n    module_path: str,\n    function_name: str,\n    verbose: bool = False,\n) -&gt; dict[str, str]:\n    \"\"\"\n    Extract argument descriptions from a function.\n\n    Args:\n        package_name: Example `fractal_tasks_core`.\n        module_path:\n            This must be an absolute path like `/some/module.py` (if\n            `package_name` is `None`) or a relative path like `something.py`\n            (if `package_name` is not `None`).\n        function_name: Example `create_ome_zarr`.\n    \"\"\"\n\n    # Extract docstring from ast.FunctionDef\n    docstring = _get_function_docstring(\n        package_name=package_name,\n        module_path=module_path,\n        function_name=function_name,\n        verbose=verbose,\n    )\n    if verbose:\n        logging.info(f\"[_get_function_args_descriptions] {docstring}\")\n\n    # Parse docstring (via docstring_parser) and prepare output\n    parsed_docstring = docparse(docstring)\n    descriptions = {\n        param.arg_name: _sanitize_description(param.description)\n        for param in parsed_docstring.params\n    }\n    logging.info(f\"[_get_function_args_descriptions] END ({function_name=})\")\n    return descriptions\n</code></pre>"},{"location":"reference/fractal_task_tools/_descriptions/#fractal_task_tools._descriptions._get_function_docstring","title":"<code>_get_function_docstring(*, package_name, module_path, function_name, verbose=False)</code>","text":"<p>Extract docstring from a function.</p> PARAMETER DESCRIPTION <code>package_name</code> <p>Example <code>fractal_tasks_core</code>.</p> <p> TYPE: <code>Optional[str]</code> </p> <code>module_path</code> <p>This must be an absolute path like <code>/some/module.py</code> (if <code>package_name</code> is <code>None</code>) or a relative path like <code>something.py</code> (if <code>package_name</code> is not <code>None</code>).</p> <p> TYPE: <code>str</code> </p> <code>function_name</code> <p>Example <code>create_ome_zarr</code>.</p> <p> TYPE: <code>str</code> </p> Source code in <code>src/fractal_task_tools/_descriptions.py</code> <pre><code>def _get_function_docstring(\n    *,\n    package_name: Optional[str],\n    module_path: str,\n    function_name: str,\n    verbose: bool = False,\n) -&gt; str:\n    \"\"\"\n    Extract docstring from a function.\n\n\n    Args:\n        package_name: Example `fractal_tasks_core`.\n        module_path:\n            This must be an absolute path like `/some/module.py` (if\n            `package_name` is `None`) or a relative path like `something.py`\n            (if `package_name` is not `None`).\n        function_name: Example `create_ome_zarr`.\n    \"\"\"\n\n    if not module_path.endswith(\".py\"):\n        raise ValueError(f\"Module {module_path} must end with '.py'\")\n\n    # Get the function ast.FunctionDef object\n    if package_name is not None:\n        if os.path.isabs(module_path):\n            raise ValueError(\n                \"Error in _get_function_docstring: `package_name` is not \"\n                \"None but `module_path` is absolute.\"\n            )\n        package_path = Path(import_module(package_name).__file__).parent\n        module_path = package_path / module_path\n    else:\n        if not os.path.isabs(module_path):\n            raise ValueError(\n                \"Error in _get_function_docstring: `package_name` is None \"\n                \"but `module_path` is not absolute.\"\n            )\n        module_path = Path(module_path)\n\n    if verbose:\n        logging.info(f\"[_get_function_docstring] {function_name=}\")\n        logging.info(f\"[_get_function_docstring] {module_path=}\")\n\n    tree = ast.parse(module_path.read_text())\n    _function = next(\n        f\n        for f in ast.walk(tree)\n        if (isinstance(f, ast.FunctionDef) and f.name == function_name)\n    )\n\n    # Extract docstring from ast.FunctionDef\n    return ast.get_docstring(_function)\n</code></pre>"},{"location":"reference/fractal_task_tools/_descriptions/#fractal_task_tools._descriptions._insert_class_attrs_descriptions","title":"<code>_insert_class_attrs_descriptions(*, schema, class_name, descriptions, definition_key)</code>","text":"<p>Merge the descriptions obtained via <code>_get_attributes_models_descriptions</code> into the <code>class_name</code> definition, within an existing JSON Schema</p> PARAMETER DESCRIPTION <code>schema</code> <p>TBD</p> <p> TYPE: <code>dict</code> </p> <code>class_name</code> <p>TBD</p> <p> TYPE: <code>str</code> </p> <code>descriptions</code> <p>TBD</p> <p> TYPE: <code>dict</code> </p> <code>definition_key</code> <p>Either <code>\"definitions\"</code> (for Pydantic V1) or <code>\"$defs\"</code> (for Pydantic V2)</p> <p> TYPE: <code>str</code> </p> Source code in <code>src/fractal_task_tools/_descriptions.py</code> <pre><code>def _insert_class_attrs_descriptions(\n    *,\n    schema: dict,\n    class_name: str,\n    descriptions: dict,\n    definition_key: str,\n):\n    \"\"\"\n    Merge the descriptions obtained via `_get_attributes_models_descriptions`\n    into the `class_name` definition, within an existing JSON Schema\n\n    Args:\n        schema: TBD\n        class_name: TBD\n        descriptions: TBD\n        definition_key: Either `\"definitions\"` (for Pydantic V1) or\n            `\"$defs\"` (for Pydantic V2)\n    \"\"\"\n    new_schema = schema.copy()\n    if definition_key not in schema:\n        return new_schema\n    else:\n        new_definitions = schema[definition_key].copy()\n    # Loop over existing definitions\n    for name, definition in schema[definition_key].items():\n        if name == class_name:\n            for prop in definition[\"properties\"]:\n                if \"description\" in new_definitions[name][\"properties\"][prop]:\n                    # This branch covers e.g. the `Field(description=\"...\")` case\n                    pass\n                else:\n                    new_definitions[name][\"properties\"][prop][\"description\"] = (\n                        descriptions[prop]\n                    )\n    new_schema[definition_key] = new_definitions\n    logging.info(\"[_insert_class_attrs_descriptions] END\")\n    return new_schema\n</code></pre>"},{"location":"reference/fractal_task_tools/_descriptions/#fractal_task_tools._descriptions._insert_function_args_descriptions","title":"<code>_insert_function_args_descriptions(*, schema, descriptions, verbose=False)</code>","text":"<p>Merge the descriptions obtained via <code>_get_args_descriptions</code> into the properties of an existing JSON Schema.</p> PARAMETER DESCRIPTION <code>schema</code> <p>TBD</p> <p> TYPE: <code>dict</code> </p> <code>descriptions</code> <p>TBD</p> <p> TYPE: <code>dict</code> </p> Source code in <code>src/fractal_task_tools/_descriptions.py</code> <pre><code>def _insert_function_args_descriptions(\n    *, schema: dict, descriptions: dict, verbose: bool = False\n):\n    \"\"\"\n    Merge the descriptions obtained via `_get_args_descriptions` into the\n    properties of an existing JSON Schema.\n\n    Args:\n        schema: TBD\n        descriptions: TBD\n    \"\"\"\n    new_schema = schema.copy()\n    new_properties = schema[\"properties\"].copy()\n    for key, value in schema[\"properties\"].items():\n        if \"description\" in value:\n            # This branch covers e.g. the `Field(description=\"...\")` case\n            pass\n        else:\n            value[\"description\"] = descriptions.get(key, \"Missing description\")\n            new_properties[key] = value\n            if verbose:\n                logging.info(\n                    f\"[_insert_function_args_descriptions] Add {key=}, {value=}\"\n                )\n    new_schema[\"properties\"] = new_properties\n    logging.info(\"[_insert_function_args_descriptions] END\")\n    return new_schema\n</code></pre>"},{"location":"reference/fractal_task_tools/_descriptions/#fractal_task_tools._descriptions._sanitize_description","title":"<code>_sanitize_description(string)</code>","text":"<p>Sanitize a description string.</p> <p>This is a provisional helper function that replaces newlines with spaces and reduces multiple contiguous whitespace characters to a single one. Future iterations of the docstrings format/parsing may render this function not-needed or obsolete.</p> PARAMETER DESCRIPTION <code>string</code> <p>TBD</p> <p> TYPE: <code>str</code> </p> Source code in <code>src/fractal_task_tools/_descriptions.py</code> <pre><code>def _sanitize_description(string: str) -&gt; str:\n    \"\"\"\n    Sanitize a description string.\n\n    This is a provisional helper function that replaces newlines with spaces\n    and reduces multiple contiguous whitespace characters to a single one.\n    Future iterations of the docstrings format/parsing may render this function\n    not-needed or obsolete.\n\n    Args:\n        string: TBD\n    \"\"\"\n    # Replace newline with space\n    new_string = string.replace(\"\\n\", \" \")\n    # Replace N-whitespace characters with a single one\n    while \"  \" in new_string:\n        new_string = new_string.replace(\"  \", \" \")\n    return new_string\n</code></pre>"},{"location":"reference/fractal_task_tools/_generatejsonschema/","title":"_generatejsonschema","text":""},{"location":"reference/fractal_task_tools/_generatejsonschema/#fractal_task_tools._generatejsonschema.CustomGenerateJsonSchema","title":"<code>CustomGenerateJsonSchema</code>","text":"<p>               Bases: <code>GenerateJsonSchema</code></p> <p>Custom JSON-Schema generator.</p> <p>General customization approach is described at https://docs.pydantic.dev/latest/concepts/json_schema/#customizing-the-json-schema-generation-process</p> Source code in <code>src/fractal_task_tools/_generatejsonschema.py</code> <pre><code>class CustomGenerateJsonSchema(GenerateJsonSchema):\n    \"\"\"\n    Custom JSON-Schema generator.\n\n    General customization approach is described at\n    https://docs.pydantic.dev/latest/concepts/json_schema/#customizing-the-json-schema-generation-process\n\n\n    \"\"\"\n\n    def get_flattened_anyof(self, schemas: list[JsonSchemaValue]) -&gt; JsonSchemaValue:\n        \"\"\"\n        Customize handling of optional fields.\n\n        As of Pydantic V2, the JSON Schema representation of model attributes\n        marked as `Optional[X]` changed, and the new behavior consists in\n        marking the corresponding properties as an `anyOf` of either a `null`\n        or the actual `X` type.\n\n        This is not always the required behavior, see e.g.\n        * https://github.com/pydantic/pydantic/issues/7161\n        * https://github.com/pydantic/pydantic/issues/8394\n\n        This method override restores the previous behavior, by stripping\n        `{\"type\": \"null\"}` from `anyOf` entries.\n        \"\"\"\n        null_schema = {\"type\": \"null\"}\n        if null_schema in schemas:\n            logger.warning(\"Drop `null_schema` before calling `get_flattened_anyof`\")\n            schemas.pop(schemas.index(null_schema))\n        return super().get_flattened_anyof(schemas)\n\n    def get_default_value(self, schema: core_schema.WithDefaultSchema) -&gt; Any:\n        \"\"\"\n        Customize default setting\n\n        This override introduces two changes with respect to the base class.\n\n        `None` defaults are stripped.\n\n        When possible, `default_factory` is used to compute the `default` value - see\n        https://github.com/pydantic/pydantic/issues/11622#issuecomment-2757419692.\n        \"\"\"\n        if \"default\" in schema:\n            if schema[\"default\"] is None:\n                logger.warning(f\"Ignore `None` default value from {schema=}\")\n                return NoDefault\n            return schema[\"default\"]\n        elif \"default_factory\" in schema:\n            if schema.get(\"default_factory_takes_data\"):\n                logger.warning(\n                    \"Cannot populate defaults based on \"\n                    f\"default_factory={schema['default_factory']}, \"\n                    f'since {schema[\"default_factory_takes_data\"]=}.'\n                )\n                return NoDefault\n            else:\n                return schema[\"default_factory\"]()\n        else:\n            return NoDefault\n</code></pre>"},{"location":"reference/fractal_task_tools/_generatejsonschema/#fractal_task_tools._generatejsonschema.CustomGenerateJsonSchema.get_default_value","title":"<code>get_default_value(schema)</code>","text":"<p>Customize default setting</p> <p>This override introduces two changes with respect to the base class.</p> <p><code>None</code> defaults are stripped.</p> <p>When possible, <code>default_factory</code> is used to compute the <code>default</code> value - see https://github.com/pydantic/pydantic/issues/11622#issuecomment-2757419692.</p> Source code in <code>src/fractal_task_tools/_generatejsonschema.py</code> <pre><code>def get_default_value(self, schema: core_schema.WithDefaultSchema) -&gt; Any:\n    \"\"\"\n    Customize default setting\n\n    This override introduces two changes with respect to the base class.\n\n    `None` defaults are stripped.\n\n    When possible, `default_factory` is used to compute the `default` value - see\n    https://github.com/pydantic/pydantic/issues/11622#issuecomment-2757419692.\n    \"\"\"\n    if \"default\" in schema:\n        if schema[\"default\"] is None:\n            logger.warning(f\"Ignore `None` default value from {schema=}\")\n            return NoDefault\n        return schema[\"default\"]\n    elif \"default_factory\" in schema:\n        if schema.get(\"default_factory_takes_data\"):\n            logger.warning(\n                \"Cannot populate defaults based on \"\n                f\"default_factory={schema['default_factory']}, \"\n                f'since {schema[\"default_factory_takes_data\"]=}.'\n            )\n            return NoDefault\n        else:\n            return schema[\"default_factory\"]()\n    else:\n        return NoDefault\n</code></pre>"},{"location":"reference/fractal_task_tools/_generatejsonschema/#fractal_task_tools._generatejsonschema.CustomGenerateJsonSchema.get_flattened_anyof","title":"<code>get_flattened_anyof(schemas)</code>","text":"<p>Customize handling of optional fields.</p> <p>As of Pydantic V2, the JSON Schema representation of model attributes marked as <code>Optional[X]</code> changed, and the new behavior consists in marking the corresponding properties as an <code>anyOf</code> of either a <code>null</code> or the actual <code>X</code> type.</p> <p>This is not always the required behavior, see e.g. * https://github.com/pydantic/pydantic/issues/7161 * https://github.com/pydantic/pydantic/issues/8394</p> <p>This method override restores the previous behavior, by stripping <code>{\"type\": \"null\"}</code> from <code>anyOf</code> entries.</p> Source code in <code>src/fractal_task_tools/_generatejsonschema.py</code> <pre><code>def get_flattened_anyof(self, schemas: list[JsonSchemaValue]) -&gt; JsonSchemaValue:\n    \"\"\"\n    Customize handling of optional fields.\n\n    As of Pydantic V2, the JSON Schema representation of model attributes\n    marked as `Optional[X]` changed, and the new behavior consists in\n    marking the corresponding properties as an `anyOf` of either a `null`\n    or the actual `X` type.\n\n    This is not always the required behavior, see e.g.\n    * https://github.com/pydantic/pydantic/issues/7161\n    * https://github.com/pydantic/pydantic/issues/8394\n\n    This method override restores the previous behavior, by stripping\n    `{\"type\": \"null\"}` from `anyOf` entries.\n    \"\"\"\n    null_schema = {\"type\": \"null\"}\n    if null_schema in schemas:\n        logger.warning(\"Drop `null_schema` before calling `get_flattened_anyof`\")\n        schemas.pop(schemas.index(null_schema))\n    return super().get_flattened_anyof(schemas)\n</code></pre>"},{"location":"reference/fractal_task_tools/_package_name_tools/","title":"_package_name_tools","text":""},{"location":"reference/fractal_task_tools/_package_name_tools/#fractal_task_tools._package_name_tools.normalize_package_name","title":"<code>normalize_package_name(pkg_name)</code>","text":"<p>Implement both PyPa and custom package-name normalization</p> <ol> <li>PyPa normalization: The name should be lowercased with all runs of the     characters <code>.</code>, <code>-</code>, or <code>_</code> replaced with a single <code>-</code> character     (https://packaging.python.org/en/latest/specifications/name-normalization).</li> <li>Custom normalization: Replace <code>-</code> with <code>_</code>, to obtain the     imported-module name.</li> </ol> PARAMETER DESCRIPTION <code>pkg_name</code> <p>The non-normalized package name.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The normalized package name.</p> Source code in <code>src/fractal_task_tools/_package_name_tools.py</code> <pre><code>def normalize_package_name(pkg_name: str) -&gt; str:\n    \"\"\"\n    Implement both PyPa and custom package-name normalization\n\n    1. PyPa normalization: The name should be lowercased with all runs of the\n        characters `.`, `-`, or `_` replaced with a single `-` character\n        (https://packaging.python.org/en/latest/specifications/name-normalization).\n    2. Custom normalization: Replace `-` with `_`, to obtain the\n        imported-module name.\n\n    Args:\n        pkg_name: The non-normalized package name.\n\n    Returns:\n        The normalized package name.\n    \"\"\"\n\n    # Apply PyPa normalization\n    pypa_normalized_package_name = re.sub(r\"[-_.]+\", \"-\", pkg_name).lower()\n\n    # Replace `-` with `_`\n    final_package_name = pypa_normalized_package_name.replace(\"-\", \"_\")\n\n    return final_package_name\n</code></pre>"},{"location":"reference/fractal_task_tools/_signature_constraints/","title":"_signature_constraints","text":""},{"location":"reference/fractal_task_tools/_signature_constraints/#fractal_task_tools._signature_constraints._extract_function","title":"<code>_extract_function(module_relative_path, function_name, package_name, verbose=False)</code>","text":"<p>Extract function from a module with the same name.</p> PARAMETER DESCRIPTION <code>package_name</code> <p>Example <code>fractal_tasks_core</code>.</p> <p> TYPE: <code>str</code> </p> <code>module_relative_path</code> <p>Example <code>tasks/create_ome_zarr.py</code>.</p> <p> TYPE: <code>str</code> </p> <code>function_name</code> <p>Example <code>create_ome_zarr</code>.</p> <p> TYPE: <code>str</code> </p> <code>verbose</code> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>src/fractal_task_tools/_signature_constraints.py</code> <pre><code>def _extract_function(\n    module_relative_path: str,\n    function_name: str,\n    package_name: str,\n    verbose: bool = False,\n) -&gt; callable:\n    \"\"\"\n    Extract function from a module with the same name.\n\n    Args:\n        package_name: Example `fractal_tasks_core`.\n        module_relative_path: Example `tasks/create_ome_zarr.py`.\n        function_name: Example `create_ome_zarr`.\n        verbose:\n    \"\"\"\n    if not module_relative_path.endswith(\".py\"):\n        raise ValueError(f\"{module_relative_path=} must end with '.py'\")\n    module_relative_path_no_py = str(Path(module_relative_path).with_suffix(\"\"))\n    module_relative_path_dots = module_relative_path_no_py.replace(\"/\", \".\")\n    if verbose:\n        logger.info(\n            f\"Now calling `import_module` for \"\n            f\"{package_name}.{module_relative_path_dots}\"\n        )\n    imported_module = import_module(f\"{package_name}.{module_relative_path_dots}\")\n    if verbose:\n        logger.info(\n            f\"Now getting attribute {function_name} from \"\n            f\"imported module {imported_module}.\"\n        )\n    task_function = getattr(imported_module, function_name)\n    return task_function\n</code></pre>"},{"location":"reference/fractal_task_tools/_signature_constraints/#fractal_task_tools._signature_constraints._recursive_union_validation","title":"<code>_recursive_union_validation(*, name, annotation, default_value, recursion_level)</code>","text":"<p>Recursive function for union validation.</p> <p>This function browses a tree of annotations, and validate the annotation of each node (if it is a union). Each Pydantic-model node then branches into additional nodes, while non-Pydantic-model nodes are the final node of their branch.</p> PARAMETER DESCRIPTION <code>annotation</code> <p>The annotation of the current node.</p> <p> TYPE: <code>Any</code> </p> <code>name</code> <p>The name of the current node.</p> <p> TYPE: <code>str</code> </p> <code>default_value</code> <p>The default value for the current node.</p> <p> TYPE: <code>Any</code> </p> <code>recursion_level</code> <p> TYPE: <code>int</code> </p> Source code in <code>src/fractal_task_tools/_signature_constraints.py</code> <pre><code>def _recursive_union_validation(\n    *,\n    name: str,\n    annotation: Any,  # FIXME type hint\n    default_value: Any,\n    recursion_level: int,\n) -&gt; None:\n    \"\"\"\n    Recursive function for union validation.\n\n    This function browses a tree of annotations, and validate the annotation of\n    each node (if it is a union). Each Pydantic-model node then branches into\n    additional nodes, while non-Pydantic-model nodes are the final node of their\n    branch.\n\n    Args:\n        annotation: The annotation of the current node.\n        name: The name of the current node.\n        default_value: The default value for the current node.\n        recursion_level:\n    \"\"\"\n\n    logger.info(\n        f\"[_recursive_union_validation] {name=}, {annotation=}, {default_value=}\"\n    )\n\n    if recursion_level &gt;= MAX_RECURSION_LEVEL:\n        raise ValueError(f\"{recursion_level=} reached {MAX_RECURSION_LEVEL}.\")\n\n    if isinstance(default_value, FieldInfo):\n        default_value = _extract_default_from_field_info(default_value)\n\n    # Validate plain unions or non-tagged annotated unions\n    if is_union(annotation):\n        logger.debug(f\"[_recursive_union_validation] {name=} is a union.\")\n        _validate_plain_union(\n            annotation=annotation,\n            name=name,\n            default_value=default_value,\n        )\n    elif is_annotated_union(annotation):\n        if not is_tagged(annotation):\n            logger.debug(\n                f\"[_recursive_union_validation] {name=} \"\n                \"is a non-tagged annotated union.\"\n            )\n            _validate_plain_union(\n                annotation=annotation.__origin__,\n                name=name,\n                default_value=default_value,\n            )\n\n    if type(annotation) is type(BaseModel):\n        for attribute_name, field_info in annotation.model_fields.items():\n            _recursive_union_validation(\n                name=f\"{name}['{attribute_name}']\",\n                annotation=annotation.__annotations__.get(\n                    attribute_name, field_info.annotation\n                ),\n                default_value=_extract_default_from_field_info(field_info),\n                recursion_level=(recursion_level + 1),\n            )\n</code></pre>"},{"location":"reference/fractal_task_tools/_signature_constraints/#fractal_task_tools._signature_constraints._validate_function_signature","title":"<code>_validate_function_signature(function)</code>","text":"<p>Validate the function signature of a task.</p> <p>Implement a set of checks for type hints that do not play well with the creation of JSON Schema, see issue 399 in <code>fractal-tasks-core</code> and issue 65 in <code>fractal-task-tools</code>.</p> PARAMETER DESCRIPTION <code>function</code> <p>A callable function.</p> <p> TYPE: <code>callable</code> </p> Source code in <code>src/fractal_task_tools/_signature_constraints.py</code> <pre><code>def _validate_function_signature(function: callable) -&gt; Signature:\n    \"\"\"\n    Validate the function signature of a task.\n\n    Implement a set of checks for type hints that do not play well with the\n    creation of JSON Schema, see issue 399 in `fractal-tasks-core` and issue\n    65 in `fractal-task-tools`.\n\n    Args:\n        function: A callable function.\n    \"\"\"\n    logger.info(f\"[_validate_function_signature] START {function.__name__}\")\n    sig = signature(function)\n    for param in sig.parameters.values():\n        # Check that name is not forbidden\n        if param.name in FORBIDDEN_PARAM_NAMES:\n            raise ValueError(\n                f\"Function {function} has argument with forbidden name '{param.name}'\"\n            )\n\n        _recursive_union_validation(\n            annotation=param.annotation,\n            name=param.name,\n            default_value=param.default,\n            recursion_level=0,\n        )\n\n    logger.info(\"[_validate_function_signature] END\")\n    return sig\n</code></pre>"},{"location":"reference/fractal_task_tools/_signature_constraints/#fractal_task_tools._signature_constraints._validate_plain_union","title":"<code>_validate_plain_union(*, name, annotation, default_value)</code>","text":"<p>Fail for known cases of invalid plain-union types.</p> <p>A plain union annotation is (by construction) one for which <code>is_union(_type) = True</code>. The only supported forms of plain unions are <code>X | None</code> or <code>X | None = None</code> (or equivalent forms).</p> <p>Note that <code>Optional[X]</code> is equivalent to <code>X | None</code> and thus it also gets validated through this function.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of the annotation to validate.</p> <p> TYPE: <code>str</code> </p> <code>annotation</code> <p>Plain-union annotation to validate. Note that this may be equal to <code>param.annotation</code> (in a non-<code>Annotated</code> case) or to <code>param.annotation.__origin__</code> (when the original annotation is an <code>Annotated</code> union).</p> <p> TYPE: <code>Any</code> </p> <code>default_value</code> <p>Default value.param: The full <code>inspect.Parameter</code> object.</p> <p> TYPE: <code>Any</code> </p> Source code in <code>src/fractal_task_tools/_signature_constraints.py</code> <pre><code>def _validate_plain_union(\n    *,\n    name: str,\n    annotation: Any,  # FIXME type hint\n    default_value: Any,\n) -&gt; None:\n    \"\"\"\n    Fail for known cases of invalid plain-union types.\n\n    A plain union annotation is (by construction) one for which\n    `is_union(_type) = True`. The only supported forms of plain unions\n    are `X | None` or `X | None = None` (or equivalent forms).\n\n    Note that `Optional[X]` is equivalent to `X | None` and thus it also gets\n    validated through this function.\n\n    Args:\n        name: Name of the annotation to validate.\n        annotation:\n            Plain-union annotation to validate. Note that this may be equal to\n            `param.annotation` (in a non-`Annotated` case) or to\n            `param.annotation.__origin__` (when the original annotation is an\n            `Annotated` union).\n        default_value: Default value.param: The full `inspect.Parameter` object.\n    \"\"\"\n\n    logger.debug(\n        f\"[_validate_plain_union] START for {name=}, {annotation=}, {default_value=}.\"\n    )\n\n    args = annotation.__args__\n    if len(args) != 2:\n        raise ValueError(\n            \"Only unions of two elements are supported, but parameter \"\n            f\"'{name}' has type hint '{annotation}'.\"\n        )\n    elif not any(arg is type(None) for arg in args):\n        raise ValueError(\n            \"One union element must be None, but parameter \"\n            f\"'{name}' has type hint '{annotation}'.\"\n        )\n    else:\n        if default_value not in (None, inspect._empty):\n            raise ValueError(\n                \"Non-None default not supported, but parameter \"\n                f\"'{name}' has type hint '{annotation}' \"\n                f\"and default {default_value}.\"\n            )\n\n    logger.debug(\n        f\"[_validate_plain_union] END for {name=}, {annotation=}, {default_value=}.\"\n    )\n</code></pre>"},{"location":"reference/fractal_task_tools/_task_arguments/","title":"_task_arguments","text":""},{"location":"reference/fractal_task_tools/_task_arguments/#fractal_task_tools._task_arguments.validate_arguments","title":"<code>validate_arguments(*, task_type, executable_kind, schema)</code>","text":"<p>Validate schema arguments against required/forbidden ones.</p> PARAMETER DESCRIPTION <code>task_type</code> <p> TYPE: <code>Literal['parallel', 'non_parallel', 'compound']</code> </p> <code>executable_kind</code> <p>The <code>parallel</code>/<code>non_parallel</code> part of the task.</p> <p> TYPE: <code>Literal['parallel', 'non_parallel']</code> </p> <code>schema</code> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>src/fractal_task_tools/_task_arguments.py</code> <pre><code>def validate_arguments(\n    *,\n    task_type: Literal[\"parallel\", \"non_parallel\", \"compound\"],\n    executable_kind: Literal[\"parallel\", \"non_parallel\"],\n    schema: dict[str, Any],\n) -&gt; None:\n    \"\"\"\n    Validate schema arguments against required/forbidden ones.\n\n    Arguments:\n        task_type:\n        executable_kind: The `parallel`/`non_parallel` part of the task.\n        schema:\n    \"\"\"\n\n    key = (task_type, executable_kind)\n    if not (key in REQUIRED_ARGUMENTS and key in FORBIDDEN_ARGUMENTS):\n        logging.error(f\"Invalid {task_type=}, {executable_kind=}.\")\n        raise ValueError(f\"Invalid {task_type=}, {executable_kind=}.\")\n\n    required_args = REQUIRED_ARGUMENTS[key]\n    forbidden_args = FORBIDDEN_ARGUMENTS[key]\n\n    schema_properties = set(schema[\"properties\"].keys())\n\n    logging.info(f\"[validate_arguments] Task has arguments: {schema_properties}\")\n    logging.info(f\"[validate_arguments] Required arguments: {required_args}\")\n    logging.info(f\"[validate_arguments] Forbidden arguments: {forbidden_args}\")\n\n    missing_required_arguments = {\n        arg for arg in required_args if arg not in schema_properties\n    }\n    if missing_required_arguments:\n        error_msg = (\n            \"[validate_arguments] Required arguments \"\n            f\"{missing_required_arguments} are missing.\"\n        )\n        logging.error(error_msg)\n        raise ValueError(error_msg)\n\n    present_forbidden_args = forbidden_args.intersection(schema_properties)\n    if present_forbidden_args:\n        error_msg = (\n            \"[validate_arguments] Forbidden arguments \"\n            f\"{present_forbidden_args} are present.\"\n        )\n        logging.error(error_msg)\n        raise ValueError(error_msg)\n</code></pre>"},{"location":"reference/fractal_task_tools/_task_docs/","title":"_task_docs","text":""},{"location":"reference/fractal_task_tools/_task_docs/#fractal_task_tools._task_docs._get_function_description","title":"<code>_get_function_description(package_name, module_path, function_name)</code>","text":"<p>Extract function description from its docstring.</p> PARAMETER DESCRIPTION <code>package_name</code> <p>Example <code>fractal_tasks_core</code>.</p> <p> TYPE: <code>str</code> </p> <code>module_path</code> <p>Example <code>tasks/create_ome_zarr.py</code>.</p> <p> TYPE: <code>str</code> </p> <code>function_name</code> <p>Example <code>create_ome_zarr</code>.</p> <p> TYPE: <code>str</code> </p> Source code in <code>src/fractal_task_tools/_task_docs.py</code> <pre><code>def _get_function_description(\n    package_name: str, module_path: str, function_name: str\n) -&gt; str:\n    \"\"\"\n    Extract function description from its docstring.\n\n    Args:\n        package_name: Example `fractal_tasks_core`.\n        module_path: Example `tasks/create_ome_zarr.py`.\n        function_name: Example `create_ome_zarr`.\n    \"\"\"\n    # Extract docstring from ast.FunctionDef\n    docstring = _get_function_docstring(\n        package_name=package_name,\n        module_path=module_path,\n        function_name=function_name,\n    )\n    # Parse docstring (via docstring_parser)\n    parsed_docstring = docparse(docstring)\n    # Combine short/long descriptions (if present)\n    short_description = parsed_docstring.short_description\n    long_description = parsed_docstring.long_description\n    items = []\n    if short_description:\n        items.append(short_description)\n    if long_description:\n        items.append(long_description)\n    if items:\n        if parsed_docstring.blank_after_short_description:\n            return \"\\n\\n\".join(items)\n        else:\n            return \"\\n\".join(items)\n    else:\n        return \"\"\n</code></pre>"},{"location":"reference/fractal_task_tools/_task_docs/#fractal_task_tools._task_docs.create_docs_info","title":"<code>create_docs_info(*, executable_non_parallel=None, executable_parallel=None, package)</code>","text":"<p>Return task description based on function docstring.</p> Source code in <code>src/fractal_task_tools/_task_docs.py</code> <pre><code>def create_docs_info(\n    *,\n    executable_non_parallel: Optional[str] = None,\n    executable_parallel: Optional[str] = None,\n    package: str,\n) -&gt; str:\n    \"\"\"\n    Return task description based on function docstring.\n    \"\"\"\n    logging.info(\"[create_docs_info] START\")\n    docs_info = []\n    for executable in [executable_non_parallel, executable_parallel]:\n        if executable is None:\n            continue\n        # Extract the function name.\n        # Note: this could be made more general, but for the moment we assume\n        # that the function has the same name as the module)\n        function_name = Path(executable).with_suffix(\"\").name\n        logging.info(f\"[create_docs_info] {function_name=}\")\n        # Get function description\n        description = _get_function_description(\n            package_name=package,\n            module_path=executable,\n            function_name=function_name,\n        )\n        docs_info.append(f\"## {function_name}\\n{description}\\n\")\n    docs_info = \"\".join(docs_info)\n    logging.info(\"[create_docs_info] END\")\n    return docs_info\n</code></pre>"},{"location":"reference/fractal_task_tools/_task_docs/#fractal_task_tools._task_docs.read_docs_info_from_file","title":"<code>read_docs_info_from_file(*, docs_info, task_list_path)</code>","text":"<p>Return task description based on the content of a file.</p> <p>An example of valid argument is <pre><code>docs_info = \"file:relative/path/info.md\"\n</code></pre> where the path is relative to the folder where <code>task_list.py</code> is.</p> Source code in <code>src/fractal_task_tools/_task_docs.py</code> <pre><code>def read_docs_info_from_file(\n    *,\n    docs_info: str,\n    task_list_path: str,\n) -&gt; str:\n    \"\"\"\n    Return task description based on the content of a file.\n\n    An example of valid argument is\n    ```\n    docs_info = \"file:relative/path/info.md\"\n    ```\n    where the path is relative to the folder where `task_list.py` is.\n    \"\"\"\n    logging.info(\"[read_docs_info_from_file] START\")\n\n    # Preliminary checks\n    if not docs_info.startswith(\"file:\"):\n        raise ValueError(f\"Invalid docs_info='{docs_info}'.\")\n    relative_path = Path(docs_info[5:])\n    if relative_path.is_absolute():\n        raise ValueError(f\"Invalid docs_info='{docs_info}' (path must be relative).\")\n\n    base_path = Path(task_list_path).parent\n    docs_path = (base_path / relative_path).as_posix()\n    logging.info(f\"[read_docs_info_from_file] Reading docs from {docs_path}\")\n    with open(docs_path, \"r\") as f:\n        docs_info = f.read()\n    logging.info(\"[read_docs_info_from_file] END\")\n\n    return docs_info\n</code></pre>"},{"location":"reference/fractal_task_tools/_titles/","title":"_titles","text":""},{"location":"reference/fractal_task_tools/_titles/#fractal_task_tools._titles._include_titles","title":"<code>_include_titles(schema, definitions_key, verbose=False)</code>","text":"<p>Include property titles, when missing.</p> <p>This handles both:</p> <ul> <li>first-level JSON Schema properties (corresponding to task     arguments);</li> <li>properties of JSON Schema definitions (corresponding to     task-argument attributes).</li> </ul> PARAMETER DESCRIPTION <code>schema</code> <p>TBD</p> <p> TYPE: <code>_Schema</code> </p> <code>definitions_key</code> <p>Either <code>\"definitions\"</code> (for Pydantic V1) or <code>\"$defs\"</code> (for Pydantic V2)</p> <p> TYPE: <code>str</code> </p> <code>verbose</code> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>src/fractal_task_tools/_titles.py</code> <pre><code>def _include_titles(\n    schema: _Schema,\n    definitions_key: str,\n    verbose: bool = False,\n) -&gt; _Schema:\n    \"\"\"\n    Include property titles, when missing.\n\n    This handles both:\n\n    - first-level JSON Schema properties (corresponding to task\n        arguments);\n    - properties of JSON Schema definitions (corresponding to\n        task-argument attributes).\n\n    Args:\n        schema: TBD\n        definitions_key: Either `\"definitions\"` (for Pydantic V1) or\n            `\"$defs\"` (for Pydantic V2)\n        verbose:\n    \"\"\"\n    new_schema = schema.copy()\n\n    if verbose:\n        logging.info(\"[_include_titles] START\")\n        logging.info(f\"[_include_titles] Input schema:\\n{schema}\")\n\n    # Update first-level properties (that is, task arguments)\n    new_properties = _include_titles_for_properties(\n        schema[\"properties\"], verbose=verbose\n    )\n    new_schema[\"properties\"] = new_properties\n\n    if verbose:\n        logging.info(\"[_include_titles] Titles for properties now included.\")\n\n    # Update properties of definitions\n    if definitions_key in schema.keys():\n        new_definitions = schema[definitions_key].copy()\n        for def_name, def_schema in new_definitions.items():\n            if \"properties\" not in def_schema.keys():\n                if verbose:\n                    logging.info(\n                        f\"Definition schema {def_name} has no 'properties' key. Skip.\"\n                    )\n            else:\n                new_properties = _include_titles_for_properties(\n                    def_schema[\"properties\"], verbose=verbose\n                )\n                new_definitions[def_name][\"properties\"] = new_properties\n        new_schema[definitions_key] = new_definitions\n\n    if verbose:\n        logging.info(\n            \"[_include_titles] Titles for definitions properties now included.\"\n        )\n        logging.info(\"[_include_titles] END\")\n    return new_schema\n</code></pre>"},{"location":"reference/fractal_task_tools/_titles/#fractal_task_tools._titles._include_titles_for_properties","title":"<code>_include_titles_for_properties(properties, verbose=False)</code>","text":"<p>Scan through properties of a JSON Schema, and set their title when it is missing.</p> <p>The title is set to <code>name.title()</code>, where <code>title</code> is a standard string method - see https://docs.python.org/3/library/stdtypes.html#str.title.</p> PARAMETER DESCRIPTION <code>properties</code> <p>TBD</p> <p> TYPE: <code>dict[str, dict]</code> </p> Source code in <code>src/fractal_task_tools/_titles.py</code> <pre><code>def _include_titles_for_properties(\n    properties: dict[str, dict],\n    verbose: bool = False,\n) -&gt; dict[str, dict]:\n    \"\"\"\n    Scan through properties of a JSON Schema, and set their title when it is\n    missing.\n\n    The title is set to `name.title()`, where `title` is a standard string\n    method - see https://docs.python.org/3/library/stdtypes.html#str.title.\n\n    Args:\n        properties: TBD\n    \"\"\"\n    if verbose:\n        logging.info(\n            f\"[_include_titles_for_properties] Original properties:\\n{properties}\"\n        )\n\n    new_properties = properties.copy()\n    for prop_name, prop in properties.items():\n        if \"title\" not in prop.keys():\n            new_prop = prop.copy()\n            new_prop[\"title\"] = prop_name.title()\n            new_properties[prop_name] = new_prop\n    if verbose:\n        logging.info(\n            f\"[_include_titles_for_properties] New properties:\\n{new_properties}\"\n        )\n    return new_properties\n</code></pre>"},{"location":"reference/fractal_task_tools/_union_types/","title":"_union_types","text":""},{"location":"reference/fractal_task_tools/_union_types/#fractal_task_tools._union_types.is_annotated_union","title":"<code>is_annotated_union(_type)</code>","text":"<p>Determine whether <code>_type</code> is <code>Annotated</code> and its wrapped type is a union.</p> <p>See https://docs.python.org/3/library/typing.html#typing.Annotated</p> Source code in <code>src/fractal_task_tools/_union_types.py</code> <pre><code>def is_annotated_union(_type) -&gt; bool:\n    \"\"\"\n    Determine whether `_type` is `Annotated` and its wrapped type is a union.\n\n    See https://docs.python.org/3/library/typing.html#typing.Annotated\n    \"\"\"\n    return typing.get_origin(_type) is typing.Annotated and is_union(_type.__origin__)\n</code></pre>"},{"location":"reference/fractal_task_tools/_union_types/#fractal_task_tools._union_types.is_tagged","title":"<code>is_tagged(_type)</code>","text":"<p>Determine whether annotations make an <code>Annotated</code> type a tagged union.</p> <p>Note that this function only gets called after <code>is_annotated_union(_type)</code> returned <code>True</code>.</p> <p>See https://docs.python.org/3/library/typing.html#typing.Annotated</p> Source code in <code>src/fractal_task_tools/_union_types.py</code> <pre><code>def is_tagged(_type) -&gt; bool:\n    \"\"\"\n    Determine whether annotations make an `Annotated` type a tagged union.\n\n    Note that this function only gets called after `is_annotated_union(_type)`\n    returned `True`.\n\n    See https://docs.python.org/3/library/typing.html#typing.Annotated\n    \"\"\"\n    return any(\n        isinstance(_item, FieldInfo) and _item.discriminator is not None\n        for _item in _type.__metadata__\n    )\n</code></pre>"},{"location":"reference/fractal_task_tools/_union_types/#fractal_task_tools._union_types.is_union","title":"<code>is_union(_type)</code>","text":"<p>Determine whether <code>_type</code> is a union.</p> <p>Based on https://docs.python.org/3/library/typing.html#typing.Union https://discuss.python.org/t/how-to-check-if-a-type-annotation-represents-an-union/77692/2.</p> Source code in <code>src/fractal_task_tools/_union_types.py</code> <pre><code>def is_union(_type) -&gt; bool:\n    \"\"\"\n    Determine whether `_type` is a union.\n\n    Based on\n    https://docs.python.org/3/library/typing.html#typing.Union\n    https://discuss.python.org/t/how-to-check-if-a-type-annotation-represents-an-union/77692/2.\n    \"\"\"\n    result = typing.get_origin(_type) in _UNION_TYPES\n    alternative_result = (\n        type(_type) is typing._UnionGenericAlias or type(_type) is types.UnionType\n    )\n    if result != alternative_result:\n        # This is a safety check, which is meant to be unreachable\n        raise ValueError(\n            f\"Could not determine whether {_type} is a union. Please report \"\n            \"this at https://github.com/fractal-analytics-platform/\"\n            \"fractal-task-tools/issues.\"\n        )\n    return result\n</code></pre>"},{"location":"reference/fractal_task_tools/logging_config/","title":"logging_config","text":""},{"location":"reference/fractal_task_tools/logging_config/#fractal_task_tools.logging_config.get_logging_format","title":"<code>get_logging_format()</code>","text":"<p>Get valid logging format from environment variable or default value.</p> Source code in <code>src/fractal_task_tools/logging_config.py</code> <pre><code>def get_logging_format() -&gt; str:\n    \"\"\"\n    Get valid logging format from environment variable or default value.\n    \"\"\"\n    # Use default value if the env variable is unset or set to an empty string\n    log_format = os.getenv(\"FRACTAL_TASK_LOG_FORMAT\") or DEFAULT_LOG_FORMAT\n    # Validate `log_format`\n    logging.PercentStyle(fmt=log_format).validate()\n    return log_format\n</code></pre>"},{"location":"reference/fractal_task_tools/logging_config/#fractal_task_tools.logging_config.get_logging_level","title":"<code>get_logging_level()</code>","text":"<p>Get valid logging level from environment variable or default value.</p> Source code in <code>src/fractal_task_tools/logging_config.py</code> <pre><code>def get_logging_level() -&gt; ValidLoggingLevel:\n    \"\"\"\n    Get valid logging level from environment variable or default value.\n    \"\"\"\n    # Use default value if the env variable is unset or set to an empty string\n    log_level = os.getenv(\"FRACTAL_TASK_LOG_LEVEL\") or DEFAULT_LOG_LEVEL\n    # Validate `log_level`\n    if log_level not in ALLOWED_LOGGING_LEVELS:\n        raise ValueError(\n            f\"Invalid FRACTAL_TASK_LOG_LEVEL={log_level} environment \"\n            f\"variable. Allowed values: {ALLOWED_LOGGING_LEVELS}.\"\n        )\n    return log_level\n</code></pre>"},{"location":"reference/fractal_task_tools/logging_config/#fractal_task_tools.logging_config.setup_logging_config","title":"<code>setup_logging_config()</code>","text":"<p>Configure root logging handler.</p> <p>Note that calling <code>logging.basicConfig</code> with <code>force=True</code> removes all existing handlers of the <code>root</code> logger and creates a new handler.</p> Source code in <code>src/fractal_task_tools/logging_config.py</code> <pre><code>def setup_logging_config() -&gt; None:\n    \"\"\"\n    Configure root logging handler.\n\n    Note that calling `logging.basicConfig` with `force=True` removes all\n    existing handlers of the `root` logger and creates a new handler.\n    \"\"\"\n    FRACTAL_TASK_LOG_LEVEL = get_logging_level()\n    FRACTAL_TASK_LOG_FORMAT = get_logging_format()\n    logging.basicConfig(\n        level=FRACTAL_TASK_LOG_LEVEL,\n        format=FRACTAL_TASK_LOG_FORMAT,\n        force=True,\n    )\n    task_wrapper_logger = logging.getLogger(WRAPPER_LOGGER_NAME)\n    task_wrapper_logger.debug(f\"Logging level: {FRACTAL_TASK_LOG_LEVEL=}\")\n    task_wrapper_logger.debug(f\"Logging format: {FRACTAL_TASK_LOG_FORMAT=}\")\n</code></pre>"},{"location":"reference/fractal_task_tools/task_models/","title":"task_models","text":""},{"location":"reference/fractal_task_tools/task_models/#fractal_task_tools.task_models.CompoundTask","title":"<code>CompoundTask</code>","text":"<p>               Bases: <code>_BaseTask</code></p> <p>A <code>CompoundTask</code> object must include both <code>executable_init</code> and <code>executable</code> attributes, and it may include the <code>meta_init</code> and <code>meta</code> attributes.</p> Source code in <code>src/fractal_task_tools/task_models.py</code> <pre><code>class CompoundTask(_BaseTask):\n    \"\"\"\n    A `CompoundTask` object must include both `executable_init` and\n    `executable` attributes, and it may include the `meta_init` and `meta`\n    attributes.\n    \"\"\"\n\n    executable_init: str\n    meta_init: Optional[dict[str, Any]] = None\n    type: Literal[\"compound\"] = \"compound\"\n\n    @property\n    def executable_non_parallel(self) -&gt; str:\n        return self.executable_init\n\n    @property\n    def meta_non_parallel(self) -&gt; Optional[dict[str, Any]]:\n        return self.meta_init\n\n    @property\n    def executable_parallel(self) -&gt; str:\n        return self.executable\n\n    @property\n    def meta_parallel(self) -&gt; Optional[dict[str, Any]]:\n        return self.meta\n</code></pre>"},{"location":"reference/fractal_task_tools/task_models/#fractal_task_tools.task_models.ConverterCompoundTask","title":"<code>ConverterCompoundTask</code>","text":"<p>               Bases: <code>_BaseTask</code></p> <p>A <code>ConverterCompoundTask</code> task is the same as a <code>CompoundTask</code>, but it is executed differently in the Fractal backend.</p> Source code in <code>src/fractal_task_tools/task_models.py</code> <pre><code>class ConverterCompoundTask(_BaseTask):\n    \"\"\"\n    A `ConverterCompoundTask` task is the same as a `CompoundTask`, but it\n    is executed differently in the Fractal backend.\n    \"\"\"\n\n    executable_init: str\n    meta_init: Optional[dict[str, Any]] = None\n    type: Literal[\"converter_compound\"] = \"converter_compound\"\n\n    @property\n    def executable_non_parallel(self) -&gt; str:\n        return self.executable_init\n\n    @property\n    def meta_non_parallel(self) -&gt; Optional[dict[str, Any]]:\n        return self.meta_init\n\n    @property\n    def executable_parallel(self) -&gt; str:\n        return self.executable\n\n    @property\n    def meta_parallel(self) -&gt; Optional[dict[str, Any]]:\n        return self.meta\n</code></pre>"},{"location":"reference/fractal_task_tools/task_models/#fractal_task_tools.task_models.ConverterNonParallelTask","title":"<code>ConverterNonParallelTask</code>","text":"<p>               Bases: <code>_BaseTask</code></p> <p>A <code>ConverterNonParallelTask</code> task is the same as a <code>NonParallelTask</code>, but it is executed differently in the Fractal backend.</p> Source code in <code>src/fractal_task_tools/task_models.py</code> <pre><code>class ConverterNonParallelTask(_BaseTask):\n    \"\"\"\n    A `ConverterNonParallelTask` task is the same as a `NonParallelTask`, but\n    it is executed differently in the Fractal backend.\n    \"\"\"\n\n    type: Literal[\"converter_non_parallel\"] = \"converter_non_parallel\"\n\n    @property\n    def executable_non_parallel(self) -&gt; str:\n        return self.executable\n\n    @property\n    def meta_non_parallel(self) -&gt; Optional[dict[str, Any]]:\n        return self.meta\n\n    @property\n    def executable_parallel(self) -&gt; None:\n        return None\n\n    @property\n    def meta_parallel(self) -&gt; None:\n        return None\n</code></pre>"},{"location":"reference/fractal_task_tools/task_models/#fractal_task_tools.task_models.NonParallelTask","title":"<code>NonParallelTask</code>","text":"<p>               Bases: <code>_BaseTask</code></p> <p>A <code>NonParallelTask</code> object must include the <code>executable</code> attribute, and it may include the <code>meta</code> attribute.</p> Source code in <code>src/fractal_task_tools/task_models.py</code> <pre><code>class NonParallelTask(_BaseTask):\n    \"\"\"\n    A `NonParallelTask` object must include the `executable` attribute, and it\n    may include the `meta` attribute.\n    \"\"\"\n\n    type: Literal[\"non_parallel\"] = \"non_parallel\"\n\n    @property\n    def executable_non_parallel(self) -&gt; str:\n        return self.executable\n\n    @property\n    def meta_non_parallel(self) -&gt; Optional[dict[str, Any]]:\n        return self.meta\n\n    @property\n    def executable_parallel(self) -&gt; None:\n        return None\n\n    @property\n    def meta_parallel(self) -&gt; None:\n        return None\n</code></pre>"},{"location":"reference/fractal_task_tools/task_models/#fractal_task_tools.task_models.ParallelTask","title":"<code>ParallelTask</code>","text":"<p>               Bases: <code>_BaseTask</code></p> <p>A <code>ParallelTask</code> object must include the <code>executable</code> attribute, and it may include the <code>meta</code> attribute.</p> Source code in <code>src/fractal_task_tools/task_models.py</code> <pre><code>class ParallelTask(_BaseTask):\n    \"\"\"\n    A `ParallelTask` object must include the `executable` attribute, and it may\n    include the `meta` attribute.\n    \"\"\"\n\n    type: Literal[\"parallel\"] = \"parallel\"\n\n    @property\n    def executable_non_parallel(self) -&gt; None:\n        return None\n\n    @property\n    def meta_non_parallel(self) -&gt; None:\n        return None\n\n    @property\n    def executable_parallel(self) -&gt; str:\n        return self.executable\n\n    @property\n    def meta_parallel(self) -&gt; Optional[dict[str, Any]]:\n        return self.meta\n</code></pre>"},{"location":"reference/fractal_task_tools/task_wrapper/","title":"task_wrapper","text":""},{"location":"reference/fractal_task_tools/task_wrapper/#fractal_task_tools.task_wrapper.TaskParameterEncoder","title":"<code>TaskParameterEncoder</code>","text":"<p>               Bases: <code>JSONEncoder</code></p> <p>Custom JSONEncoder that transforms Path objects to strings.</p> <p>Ref https://docs.python.org/3/library/json.html</p> Source code in <code>src/fractal_task_tools/task_wrapper.py</code> <pre><code>class TaskParameterEncoder(JSONEncoder):\n    \"\"\"\n    Custom JSONEncoder that transforms Path objects to strings.\n\n    Ref https://docs.python.org/3/library/json.html\n    \"\"\"\n\n    def default(self, obj):\n        if isinstance(obj, Path):\n            return obj.as_posix()\n        return super().default(obj)\n</code></pre>"},{"location":"reference/fractal_task_tools/task_wrapper/#fractal_task_tools.task_wrapper._check_deprecated_argument","title":"<code>_check_deprecated_argument(logger_name=None)</code>","text":"<p>Emit warning for deprecated argument.</p> Source code in <code>src/fractal_task_tools/task_wrapper.py</code> <pre><code>def _check_deprecated_argument(logger_name: str | None = None) -&gt; None:\n    \"\"\"\n    Emit warning for deprecated argument.\n    \"\"\"\n    if logger_name is not None:\n        task_wrapper_logger.warning(\n            (\n                \"`logger_name` function argument is deprecated. \"\n                f\"The value provided ({logger_name}) will be ignored.\"\n            )\n        )\n</code></pre>"},{"location":"reference/fractal_task_tools/task_wrapper/#fractal_task_tools.task_wrapper.run_fractal_task","title":"<code>run_fractal_task(*, task_function, skip_logging_configuration=False, logger_name=None)</code>","text":"<p>Implement standard task interface and call task_function.</p> PARAMETER DESCRIPTION <code>task_function</code> <p>Callable function that runs the task.</p> <p> TYPE: <code>callable</code> </p> <code>skip_logging_configuration</code> <p>If <code>True</code>, do not call override logging configuration.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>logger_name</code> <p>Deprecated argument (will be removed in a future version)</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> Source code in <code>src/fractal_task_tools/task_wrapper.py</code> <pre><code>def run_fractal_task(\n    *,\n    task_function: callable,\n    skip_logging_configuration: bool = False,\n    logger_name: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Implement standard task interface and call task_function.\n\n    Args:\n        task_function:\n            Callable function that runs the task.\n        skip_logging_configuration:\n            If `True`, do not call override logging configuration.\n        logger_name:\n            Deprecated argument (will be removed in a future version)\n    \"\"\"\n\n    # Parse `--args-json` and `--out-json` CLI arguments\n    parser = ArgumentParser()\n    parser.add_argument(\n        \"--args-json\",\n        help=\"Read parameters from json file\",\n        required=True,\n        type=str,\n    )\n    parser.add_argument(\n        \"--out-json\",\n        help=\"Output file to redirect serialised returned data\",\n        required=True,\n        type=str,\n    )\n    parsed_args = parser.parse_args()\n\n    # Configure root logger\n    if not (\n        skip_logging_configuration\n        or os.getenv(\n            \"FRACTAL_TASK_SKIP_LOG_CONFIG\",\n            False,\n        )\n    ):\n        setup_logging_config()\n\n    _check_deprecated_argument(logger_name)\n\n    # Preliminary check\n    if Path(parsed_args.out_json).exists():\n        msg = f\"Output file {parsed_args.out_json} already exists. Terminating\"\n        task_wrapper_logger.error(msg)\n        sys.exit(msg)\n\n    # Read parameters dictionary\n    with open(parsed_args.args_json, \"r\") as f:\n        pars = json.load(f)\n\n    # Run task\n    task_wrapper_logger.info(f\"START {task_function.__name__} task\")\n    metadata_update = task_function(**pars)\n    task_wrapper_logger.info(f\"END {task_function.__name__} task\")\n\n    # Write output metadata to file, with custom JSON encoder\n    with open(parsed_args.out_json, \"w\") as fout:\n        json.dump(\n            metadata_update,\n            fout,\n            cls=TaskParameterEncoder,\n            indent=2,\n        )\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>The <code>fractal-task-tools</code> package includes two main features:</p> <ol> <li>A tool to build the manifest for a package of Fractal tasks.</li> <li>A wrapper to run a Python task function as a standard command-line interface.</li> </ol> <p>Note: these features were previously part of the <code>fractal-tasks-core</code> package. Here is a description of how to migrate a tasks package to <code>fractal-task-tools</code>.</p>"},{"location":"usage/install/","title":"How to install","text":"<p>Fractal Task Tools is hosted on the PyPI index, and it can be installed with <code>pip</code> via <pre><code>pip install fractal-task-tools\n</code></pre></p>"},{"location":"usage/legacy/","title":"Migrate from legacy","text":"<ol> <li>Add <code>fractal-task-tools</code> as a required dependency for your task package.</li> <li> <p>In the <code>task_list.py</code> file of your package, import task models from <code>fractal_task_tools.task_models</code> (rather than <code>fractal_tasks_core.dev.task_models</code>), as in <pre><code>from fractal_task_tools.task_models import CompoundTask\nfrom fractal_task_tools.task_models import NonParallelTask\nfrom fractal_task_tools.task_models import ConverterCompoundTask\nfrom fractal_task_tools.task_models import ConverterNonParallelTask\nfrom fractal_task_tools.task_models import ParallelTask\n</code></pre></p> </li> <li> <p>If some of your tasks are converters (that is, they create OME-Zarr images but do not take any OME-Zarr image as an input), you can now use one of the new available task types (<code>ConverterCompoundTask</code> and <code>ConverterNonParallelTask</code>).</p> </li> <li> <p>In the <code>task_list.py</code> file of your package, optionally include variables for <code>AUTHORS</code>, <code>DOCS_LINK</code> and <code>INPUT_MODELS</code> (if applicable), as in this example: <pre><code>AUTHORS = \"Fractal Core Team\"\nDOCS_LINK = \"https://fractal-analytics-platform.github.io/fractal-tasks-core\"\nINPUT_MODELS = [\n    [\"fractal_tasks_core\", \"channels.py\", \"OmeroChannel\"],\n    [\"fractal_tasks_core\", \"channels.py\", \"Window\"],\n    [\"fractal_tasks_core\", \"channels.py\", \"ChannelInputModel\"],\n    ...\n  ]\n</code></pre></p> </li> <li> <p>In order to create the manifest for your package and write it to disk (within the root directory of the installed package), use <pre><code>fractal-manifest create --package my-fractal-tasks-package\n</code></pre> This command replaces the custom <code>create_manifest.py</code> script, that you can now delete.</p> </li> <li> <p>In order to check that the manifest for your package is up to date (e.g. from within the CI), use <pre><code>fractal-manifest check --package my-fractal-tasks-package\n</code></pre> This command replaces the custom logic often included in GitHub Actions, which re-creates the manifest and then run a <code>git diff</code> to see if it changed.</p> </li> <li> <p>For each one of your tasks' modules, replace the <code>import</code> from <code>fractal_tasks_core.tasks._utils</code> with <pre><code>from fractal_task_tools.task_wrapper import run_fractal_task\n</code></pre></p> </li> </ol>"},{"location":"usage/manifest/","title":"Tasks manifest","text":""},{"location":"usage/manifest/#build-and-check-manifest","title":"Build and check manifest","text":"<p><code>fractal-task-tools</code> includes a set of task models, to be used in the <code>task_list.py</code> module. See the following example from the <code>fractal-tasks-core</code> package: <pre><code>from fractal_task_tools.task_models import ConverterCompoundTask\n\nTASK_LIST = [\n    ConverterCompoundTask(\n        name=\"Convert Cellvoyager to OME-Zarr\",\n        executable_init=\"tasks/cellvoyager_to_ome_zarr_init.py\",\n        executable=\"tasks/cellvoyager_to_ome_zarr_compute.py\",\n        meta_init={\"cpus_per_task\": 1, \"mem\": 4000},\n        meta={\"cpus_per_task\": 1, \"mem\": 4000},\n        category=\"Conversion\",\n        modality=\"HCS\",\n        tags=[\"Yokogawa\", \"Cellvoyager\", \"2D\", \"3D\"],\n        docs_info=\"file:task_info/convert_cellvoyager_to_ome_zarr.md\",\n    ),\n]\n</code></pre></p> <p>Once the <code>task_list.py</code> module is defined, <code>fractal-task-tools</code> also includes a command-line interface for creating and checking a manifest file.</p> <p>The <code>create</code> command can be used as in <pre><code>fractal-manifest create --package my-task-package\n</code></pre> and it writes the manifest to a file called <code>__FRACTAL_MANIFEST__.json</code>, in the root folder where the package <code>my-task-package</code> is installed.</p> <p>The <code>check</code> command can be used as in <pre><code>fractal-manifest check --package my-task-package\n</code></pre> and it verifies that the on-disk manifest is up-to-date, which is useful e.g. as a continuous-integration step:</p>"},{"location":"usage/manifest/#json-schemas","title":"JSON Schemas","text":"<p>Each task listed in the manifest is associated to a JSON Schema that represents its arguments (or two schemas, if the task has both a non-parallel and a parallel unit). These schemas are stored in the <code>args_schema_non_parallel</code> and <code>args_schema_parallel</code> properties of each task.</p> <p>This kind of schemas are not used at task runtime (where the validity of task arguments is typically enforced by the <code>@pydantic.validate_call</code> decorator), but they form the basis for constructing the <code>fractal-web</code> user interface that lets a user edit task arguments.</p> <p>The <code>args_schema_version</code> property, which is set at the manifest level, determines a set of constraints on the task-arguments schemas. What is described below applies to the current one as of <code>fractal-task-tools=0.4.0a3</code>, named <code>args_schema_version = \"pydantic_v2\"</code>. The discussion about an upcoming specification is tracked at https://github.com/fractal-analytics-platform/fractal-task-tools/issues/97.</p>"},{"location":"usage/manifest/#restrictions-on-task-functions","title":"Restrictions on task functions","text":"<p>Some patterns are forbidden in the Python functions representing Fractal tasks.</p>"},{"location":"usage/manifest/#argument-names","title":"Argument names","text":"<p>The following keywords are reserved and cannot be used for a task-argument name:</p> <ul> <li><code>\"args\"</code></li> <li><code>\"kwargs\"</code></li> <li><code>\"v__args\"</code></li> <li><code>\"v__kwargs\"</code></li> <li><code>\"v__duplicate_kwargs\"</code></li> <li><code>\"v__positional_only\"</code></li> </ul>"},{"location":"usage/manifest/#union-types","title":"Union types","text":"<p>When top-level task arguments or nested properties have a union type annotation, it must be one of the two supported cases described below</p>"},{"location":"usage/manifest/#supported-case-1-plain-binary-unions-with-none","title":"Supported case 1: Plain binary unions with <code>None</code>","text":"<p>The first supported case is the one of an union of a given type and <code>None</code>. If the default is set, it must be <code>None</code>. Here are some examples of supported and non-supported type annotations for task arguments: <pre><code>from pydantic import Field\n\ndef task_function_ok(\n    arg1: int | None,\n    arg2: int | None = None,\n    arg3: int | None = Field(default=None),\n    arg4: int | None = Field(default_factory=lambda: None),\n    arg5: Optional[int],\n    arg6: Annotated[int | None, \"a comment\"],\n    arg7: Annotated[int | None, \"a comment\"] = None,\n    arg8: Annotated[int | None, \"a comment\"] = Field(default=None),\n    arg9: int | None = Field(default_factory=lambda _: 7),  # Since the factory requires additional data, it is ignored and the default is not populated.\n):\n    pass\n\ndef task_function_bad(\n    arg1: int | str,\n    arg2: int | str | None,\n    arg3: int | None = 1,\n    arg4: int | None = Field(default=1),\n    arg5: int | None = Field(default_factory=lambda: 1),\n):\n    pass\n</code></pre></p>"},{"location":"usage/manifest/#supported-case-2-tagged-unions","title":"Supported case 2: Tagged unions","text":"<p>The second supported case is the one of a tagged union, see e.g. https://docs.pydantic.dev/latest/concepts/unions/#discriminated-unions-with-str-discriminators.</p> <p>Here is a supported example: <pre><code>from typing import Literal\nfrom typing import Annotated\n\nclass Model1(BaseModel):\n    label: Literal[\"label1\"] = \"label1\"\n    field1: int = 1\n\n\nclass Model2(BaseModel):\n    label: Literal[\"label2\"] = \"label2\"\n    field1: int\n    field2: str\n\nMyTaggedUnion = Annotated[Model1 | Model2, Field(discriminator=\"label\")]\n\ndef task_function_ok(\n    arg1: MyTaggedUnion,\n):\n    pass\n</code></pre></p>"},{"location":"usage/manifest/#customizations-of-schema-generation","title":"Customizations of schema generation","text":"<p>The general approach for customizing the Pydantic schema-generation procedure is described at https://docs.pydantic.dev/latest/concepts/json_schema/#customizing-the-json-schema-generation-process.</p> <p>In <code>fractal-task-tools</code>, this includes the following customizations (which are applied at all levels, that is, both for top-level task arguments and for nested properties):</p> <ol> <li>When the generated schema includes an <code>anyOf</code> array, we remove any <code>{\"type\": \"null\"}</code> element from it.</li> <li>When the generated schema includes a <code>default</code> value which is set to <code>null</code>, we remove it.</li> <li>The the type annotation is a <code>Field</code> with a <code>default_factory</code> which is set and which does not require any argument, we compute the <code>default</code> value as <code>default_factory()</code>.</li> </ol>"},{"location":"usage/run_task/","title":"Run a task","text":"<p>Within the Fractal framework, tasks are run as executable commands with a given signature, which looks like <pre><code>python task.py --args-json /path/to/arguments.json --out-json /path/to/output/metadata.json\n</code></pre></p> <p>The <code>run_fractal_task</code> wrapper converts a Python function into such a command-line interface. It can be used by writing a task Python module like my_task.py<pre><code>from pydantic import validate_call\n\n@validate_call\ndef my_task(\n    zarr_url: str,\n    argument_1: int,\n):\n    # This is the task function, which performs some image-processing task\n    # ...\n\nif __name__ == \"__main__\":\n    from fractal_task_tools.task_wrapper import run_fractal_task\n    run_fractal_task(task_function=my_task)\n</code></pre> where the <code>if __name__ == \"__main__\"</code> block at the end is the one introducing the proper command-line interface.</p>"},{"location":"usage/run_task/#log-configuration","title":"Log configuration","text":"<p>By default, the task wrapper sets a default format (<code>%(asctime)s; %(name)s; %(levelname)s; %(message)s</code>) and a default logging level (<code>INFO</code>) loggers based on the Python <code>logging</code> library. As an example, when running the following updated version of the example above my_task_with_logs.py<pre><code>import logging\nfrom pydantic import validate_call\n\nlogger = logging.getLogger(\"my_task_with_logs\")\n\n@validate_call\ndef my_task_with_logs(\n    zarr_url: str,\n    argument_1: int,\n):\n    # This is the task function, which performs some image-processing task\n    # ...\n\n    logger.debug(f\"Here is a DEBUG log from the task.\")\n    logger.info(f\"Here is an INFO log from the task.\")\n    logger.warning(\"Here is a WARNING log from the task\")\n\nif __name__ == \"__main__\":\n    from fractal_task_tools.task_wrapper import run_fractal_task\n    run_fractal_task(task_function=my_task_with_logs)\n</code></pre> the logs look like <pre><code>2026-02-10 09:31:33,338; run_fractal_task; INFO; START my_task task\n2026-02-10 09:31:33,338; my_task_with_logs; INFO; Here is an INFO log from the task.\n2026-02-10 09:31:33,339; my_task_with_logs; WARNING; Here is a WARNING log from the task\n2026-02-10 09:31:33,339; run_fractal_task; INFO; END my_task task\n</code></pre></p> <p>The task developer can fully disable any logging configuration in the task wrapper by calling it as in <pre><code>run_fractal_task(task_function=my_task_with_logs, skip_logging_configuration=True)\n</code></pre></p> <p>The task user can customize the default format and logging level by setting any of the following environment variables:</p> <ul> <li><code>FRACTAL_TASK_LOG_LEVEL</code>, which must be a value in <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, or <code>CRITICAL</code>.</li> <li><code>FRACTAL_TASK_LOG_FORMAT</code>, which must be in the same style as the default value (<code>%(asctime)s; %(name)s; %(levelname)s; %(message)s</code>) and can include any attribute from https://docs.python.org/3/library/logging.html#logrecord-attributes.</li> <li><code>FRACTAL_TASK_SKIP_LOG_CONFIG</code>: whenever this is set (to any arbitrary value), it has the same effect as <code>skip_logging_configuration=True</code>.</li> </ul>"}]}